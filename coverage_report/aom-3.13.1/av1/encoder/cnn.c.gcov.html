<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.info - aom-3.13.1/av1/encoder/cnn.c</title>
  <link rel="stylesheet" type="text/css" href="../../../gcov.css">
</head>

<body>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="title">LCOV - code coverage report</td></tr>
            <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>

            <tr>
              <td width="100%">
                <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="10%" class="headerValue"><a href="../../../index.html">top level</a> - <a href="index.html">aom-3.13.1/av1/encoder</a> - cnn.c<span style="font-size: 80%;"> (source / <a href="cnn.c.func-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="5%"></td>
            <td width="5%" class="headerCovTableHead">Coverage</td>
            <td width="5%" class="headerCovTableHead" title="Covered + Uncovered code">Total</td>
            <td width="5%" class="headerCovTableHead" title="Exercised code only">Hit</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntryLo">0.0&nbsp;%</td>
            <td class="headerCovTableEntry">859</td>
            <td class="headerCovTableEntry">0</td>
          </tr>
          <tr>
            <td class="headerItem">Test Date:</td>
            <td class="headerValue">2026-02-03 17:29:02</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntryLo">0.0&nbsp;%</td>
            <td class="headerCovTableEntry">32</td>
            <td class="headerCovTableEntry">0</td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
            | Branches:
            <span class="coverLegendCov">+</span> taken
            <span class="coverLegendNoCov">-</span> not taken
            <span class="coverLegendNoCov">#</span> not executed
</td>
            <td></td>
            <td class="headerItem">Branches:</td>
            <td class="headerCovTableEntryHi">-</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">0</td>
          </tr>
                  <tr><td><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
                </table>
              </td>
            </tr>

            <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
          </table>

          <table cellpadding=0 cellspacing=0 border=0>
            <tr>
              <td><br></td>
            </tr>
            <tr>
              <td>
<pre class="sourceHeading">             Branch data     Line data    Source code</pre>
<pre class="source">
<span id="L1"><span class="lineNum">       1</span>                 :             : /*</span>
<span id="L2"><span class="lineNum">       2</span>                 :             :  * Copyright (c) 2019, Alliance for Open Media. All rights reserved.</span>
<span id="L3"><span class="lineNum">       3</span>                 :             :  *</span>
<span id="L4"><span class="lineNum">       4</span>                 :             :  * This source code is subject to the terms of the BSD 2 Clause License and</span>
<span id="L5"><span class="lineNum">       5</span>                 :             :  * the Alliance for Open Media Patent License 1.0. If the BSD 2 Clause License</span>
<span id="L6"><span class="lineNum">       6</span>                 :             :  * was not distributed with this source code in the LICENSE file, you can</span>
<span id="L7"><span class="lineNum">       7</span>                 :             :  * obtain it at www.aomedia.org/license/software. If the Alliance for Open</span>
<span id="L8"><span class="lineNum">       8</span>                 :             :  * Media Patent License 1.0 was not distributed with this source code in the</span>
<span id="L9"><span class="lineNum">       9</span>                 :             :  * PATENTS file, you can obtain it at www.aomedia.org/license/patent.</span>
<span id="L10"><span class="lineNum">      10</span>                 :             :  */</span>
<span id="L11"><span class="lineNum">      11</span>                 :             : </span>
<span id="L12"><span class="lineNum">      12</span>                 :             : #include &lt;assert.h&gt;</span>
<span id="L13"><span class="lineNum">      13</span>                 :             : #include &lt;math.h&gt;</span>
<span id="L14"><span class="lineNum">      14</span>                 :             : #include &lt;stdbool.h&gt;</span>
<span id="L15"><span class="lineNum">      15</span>                 :             : </span>
<span id="L16"><span class="lineNum">      16</span>                 :             : #include &quot;aom_dsp/aom_dsp_common.h&quot;</span>
<span id="L17"><span class="lineNum">      17</span>                 :             : #include &quot;av1/common/av1_common_int.h&quot;</span>
<span id="L18"><span class="lineNum">      18</span>                 :             : #include &quot;av1/encoder/cnn.h&quot;</span>
<span id="L19"><span class="lineNum">      19</span>                 :             : </span>
<span id="L20"><span class="lineNum">      20</span>                 :             : #define CLAMPINDEX(a, hi) ((a) &lt; 0 ? 0 : ((a) &gt;= (hi) ? ((hi) - 1) : (a)))</span>
<span id="L21"><span class="lineNum">      21</span>                 :             : </span>
<span id="L22"><span class="lineNum">      22</span>                 :             : typedef struct {</span>
<span id="L23"><span class="lineNum">      23</span>                 :             :   const float **input;</span>
<span id="L24"><span class="lineNum">      24</span>                 :             :   int in_width;</span>
<span id="L25"><span class="lineNum">      25</span>                 :             :   int in_height;</span>
<span id="L26"><span class="lineNum">      26</span>                 :             :   int in_stride;</span>
<span id="L27"><span class="lineNum">      27</span>                 :             :   const CNN_LAYER_CONFIG *layer_config;</span>
<span id="L28"><span class="lineNum">      28</span>                 :             :   float **output;</span>
<span id="L29"><span class="lineNum">      29</span>                 :             :   int out_stride;</span>
<span id="L30"><span class="lineNum">      30</span>                 :             :   int start_idx;</span>
<span id="L31"><span class="lineNum">      31</span>                 :             :   int th_step;</span>
<span id="L32"><span class="lineNum">      32</span>                 :             : } CONVOLVE_OPS;</span>
<span id="L33"><span class="lineNum">      33</span>                 :             : </span>
<span id="L34"><span class="lineNum">      34</span>                 :<span class="tlaUNC tlaBgUNC">           0 : static inline float softsign(float x) { return x / (fabsf(x) + 1.0f); }</span></span>
<span id="L35"><span class="lineNum">      35</span>                 :             : </span>
<span id="L36"><span class="lineNum">      36</span>                 :<span class="tlaUNC">           0 : static inline float relu(float x) { return (x &lt; 0) ? 0 : x; }</span></span>
<span id="L37"><span class="lineNum">      37</span>                 :             : </span>
<span id="L38"><span class="lineNum">      38</span>                 :             : typedef struct {</span>
<span id="L39"><span class="lineNum">      39</span>                 :             :   int allocsize;</span>
<span id="L40"><span class="lineNum">      40</span>                 :             :   int channels;</span>
<span id="L41"><span class="lineNum">      41</span>                 :             :   int width, height, stride;</span>
<span id="L42"><span class="lineNum">      42</span>                 :             :   float *buf[CNN_MAX_CHANNELS];</span>
<span id="L43"><span class="lineNum">      43</span>                 :             : } TENSOR;</span>
<span id="L44"><span class="lineNum">      44</span>                 :             : </span>
<span id="L45"><span class="lineNum">      45</span>                 :<span class="tlaUNC">           0 : static void init_tensor(TENSOR *tensor) { memset(tensor, 0, sizeof(*tensor)); }</span></span>
<span id="L46"><span class="lineNum">      46</span>                 :             : </span>
<span id="L47"><span class="lineNum">      47</span>                 :<span class="tlaUNC">           0 : static void free_tensor(TENSOR *tensor) {</span></span>
<span id="L48"><span class="lineNum">      48</span>                 :<span class="tlaUNC">           0 :   if (tensor-&gt;allocsize) {</span></span>
<span id="L49"><span class="lineNum">      49</span>                 :<span class="tlaUNC">           0 :     aom_free(tensor-&gt;buf[0]);</span></span>
<span id="L50"><span class="lineNum">      50</span>                 :<span class="tlaUNC">           0 :     tensor-&gt;buf[0] = NULL;</span></span>
<span id="L51"><span class="lineNum">      51</span>                 :<span class="tlaUNC">           0 :     tensor-&gt;allocsize = 0;</span></span>
<span id="L52"><span class="lineNum">      52</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L53"><span class="lineNum">      53</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L54"><span class="lineNum">      54</span>                 :             : </span>
<span id="L55"><span class="lineNum">      55</span>                 :<span class="tlaUNC">           0 : static bool realloc_tensor(TENSOR *tensor, int channels, int width,</span></span>
<span id="L56"><span class="lineNum">      56</span>                 :             :                            int height) {</span>
<span id="L57"><span class="lineNum">      57</span>                 :<span class="tlaUNC">           0 :   const int newallocsize = channels * width * height;</span></span>
<span id="L58"><span class="lineNum">      58</span>                 :<span class="tlaUNC">           0 :   if (tensor-&gt;allocsize &lt; newallocsize) {</span></span>
<span id="L59"><span class="lineNum">      59</span>                 :<span class="tlaUNC">           0 :     free_tensor(tensor);</span></span>
<span id="L60"><span class="lineNum">      60</span>                 :<span class="tlaUNC">           0 :     tensor-&gt;buf[0] =</span></span>
<span id="L61"><span class="lineNum">      61</span>                 :<span class="tlaUNC">           0 :         (float *)aom_malloc(sizeof(*tensor-&gt;buf[0]) * newallocsize);</span></span>
<span id="L62"><span class="lineNum">      62</span>                 :<span class="tlaUNC">           0 :     if (!tensor-&gt;buf[0]) return false;</span></span>
<span id="L63"><span class="lineNum">      63</span>                 :<span class="tlaUNC">           0 :     tensor-&gt;allocsize = newallocsize;</span></span>
<span id="L64"><span class="lineNum">      64</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L65"><span class="lineNum">      65</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;width = width;</span></span>
<span id="L66"><span class="lineNum">      66</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;height = height;</span></span>
<span id="L67"><span class="lineNum">      67</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;stride = width;</span></span>
<span id="L68"><span class="lineNum">      68</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;channels = channels;</span></span>
<span id="L69"><span class="lineNum">      69</span>                 :<span class="tlaUNC">           0 :   for (int c = 1; c &lt; channels; ++c)</span></span>
<span id="L70"><span class="lineNum">      70</span>                 :<span class="tlaUNC">           0 :     tensor-&gt;buf[c] = &amp;tensor-&gt;buf[0][c * width * height];</span></span>
<span id="L71"><span class="lineNum">      71</span>                 :<span class="tlaUNC">           0 :   return true;</span></span>
<span id="L72"><span class="lineNum">      72</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L73"><span class="lineNum">      73</span>                 :             : </span>
<span id="L74"><span class="lineNum">      74</span>                 :<span class="tlaUNC">           0 : static void copy_tensor(const TENSOR *src, int copy_channels, int dst_offset,</span></span>
<span id="L75"><span class="lineNum">      75</span>                 :             :                         TENSOR *dst) {</span>
<span id="L76"><span class="lineNum">      76</span>                 :             :   assert(src-&gt;width == dst-&gt;width);</span>
<span id="L77"><span class="lineNum">      77</span>                 :             :   assert(src-&gt;height == dst-&gt;height);</span>
<span id="L78"><span class="lineNum">      78</span>                 :             :   assert(copy_channels &lt;= src-&gt;channels);</span>
<span id="L79"><span class="lineNum">      79</span>                 :<span class="tlaUNC">           0 :   if (src-&gt;stride == dst-&gt;width &amp;&amp; dst-&gt;stride == dst-&gt;width) {</span></span>
<span id="L80"><span class="lineNum">      80</span>                 :<span class="tlaUNC">           0 :     for (int c = 0; c &lt; copy_channels; ++c) {</span></span>
<span id="L81"><span class="lineNum">      81</span>                 :<span class="tlaUNC">           0 :       memcpy(dst-&gt;buf[dst_offset + c], src-&gt;buf[c],</span></span>
<span id="L82"><span class="lineNum">      82</span>                 :<span class="tlaUNC">           0 :              sizeof(*dst-&gt;buf[0]) * src-&gt;width * src-&gt;height);</span></span>
<span id="L83"><span class="lineNum">      83</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L84"><span class="lineNum">      84</span>                 :<span class="tlaUNC">           0 :   } else {</span></span>
<span id="L85"><span class="lineNum">      85</span>                 :<span class="tlaUNC">           0 :     for (int c = 0; c &lt; copy_channels; ++c) {</span></span>
<span id="L86"><span class="lineNum">      86</span>                 :<span class="tlaUNC">           0 :       for (int r = 0; r &lt; dst-&gt;height; ++r) {</span></span>
<span id="L87"><span class="lineNum">      87</span>                 :<span class="tlaUNC">           0 :         memcpy(&amp;dst-&gt;buf[dst_offset + c][r * dst-&gt;stride],</span></span>
<span id="L88"><span class="lineNum">      88</span>                 :<span class="tlaUNC">           0 :                &amp;src-&gt;buf[c][r * src-&gt;stride],</span></span>
<span id="L89"><span class="lineNum">      89</span>                 :<span class="tlaUNC">           0 :                dst-&gt;width * sizeof(*dst-&gt;buf[c]));</span></span>
<span id="L90"><span class="lineNum">      90</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L91"><span class="lineNum">      91</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L92"><span class="lineNum">      92</span>                 :             :   }</span>
<span id="L93"><span class="lineNum">      93</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L94"><span class="lineNum">      94</span>                 :             : </span>
<span id="L95"><span class="lineNum">      95</span>                 :<span class="tlaUNC">           0 : static void assign_tensor(TENSOR *tensor, float *buf[CNN_MAX_CHANNELS],</span></span>
<span id="L96"><span class="lineNum">      96</span>                 :             :                           int channels, int width, int height, int stride) {</span>
<span id="L97"><span class="lineNum">      97</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;allocsize = 0;</span></span>
<span id="L98"><span class="lineNum">      98</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;channels = channels;</span></span>
<span id="L99"><span class="lineNum">      99</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;width = width;</span></span>
<span id="L100"><span class="lineNum">     100</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;height = height;</span></span>
<span id="L101"><span class="lineNum">     101</span>                 :<span class="tlaUNC">           0 :   tensor-&gt;stride = stride;</span></span>
<span id="L102"><span class="lineNum">     102</span>                 :<span class="tlaUNC">           0 :   if (buf) {</span></span>
<span id="L103"><span class="lineNum">     103</span>                 :<span class="tlaUNC">           0 :     for (int c = 0; c &lt; channels; ++c) tensor-&gt;buf[c] = buf[c];</span></span>
<span id="L104"><span class="lineNum">     104</span>                 :<span class="tlaUNC">           0 :   } else {</span></span>
<span id="L105"><span class="lineNum">     105</span>                 :<span class="tlaUNC">           0 :     for (int c = 0; c &lt; channels; ++c) tensor-&gt;buf[c] = NULL;</span></span>
<span id="L106"><span class="lineNum">     106</span>                 :             :   }</span>
<span id="L107"><span class="lineNum">     107</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L108"><span class="lineNum">     108</span>                 :             : </span>
<span id="L109"><span class="lineNum">     109</span>                 :<span class="tlaUNC">           0 : static void swap_tensor(TENSOR *t1, TENSOR *t2) {</span></span>
<span id="L110"><span class="lineNum">     110</span>                 :<span class="tlaUNC">           0 :   TENSOR t = *t1;</span></span>
<span id="L111"><span class="lineNum">     111</span>                 :<span class="tlaUNC">           0 :   *t1 = *t2;</span></span>
<span id="L112"><span class="lineNum">     112</span>                 :<span class="tlaUNC">           0 :   *t2 = t;</span></span>
<span id="L113"><span class="lineNum">     113</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L114"><span class="lineNum">     114</span>                 :             : </span>
<span id="L115"><span class="lineNum">     115</span>                 :             : // The concatenated tensor goes into dst with first the channels in</span>
<span id="L116"><span class="lineNum">     116</span>                 :             : // original dst followed by the channels in the src</span>
<span id="L117"><span class="lineNum">     117</span>                 :<span class="tlaUNC">           0 : static bool concat_tensor(const TENSOR *src, TENSOR *dst) {</span></span>
<span id="L118"><span class="lineNum">     118</span>                 :             :   assert(src-&gt;width == dst-&gt;width);</span>
<span id="L119"><span class="lineNum">     119</span>                 :             :   assert(src-&gt;height == dst-&gt;height);</span>
<span id="L120"><span class="lineNum">     120</span>                 :             : </span>
<span id="L121"><span class="lineNum">     121</span>                 :<span class="tlaUNC">           0 :   const int dst_channels = dst-&gt;channels;</span></span>
<span id="L122"><span class="lineNum">     122</span>                 :<span class="tlaUNC">           0 :   const int channels = dst-&gt;channels + src-&gt;channels;</span></span>
<span id="L123"><span class="lineNum">     123</span>                 :<span class="tlaUNC">           0 :   const int newallocsize = channels * dst-&gt;width * dst-&gt;height;</span></span>
<span id="L124"><span class="lineNum">     124</span>                 :<span class="tlaUNC">           0 :   if (dst-&gt;allocsize &lt; newallocsize) {</span></span>
<span id="L125"><span class="lineNum">     125</span>                 :<span class="tlaUNC">           0 :     TENSOR t;</span></span>
<span id="L126"><span class="lineNum">     126</span>                 :<span class="tlaUNC">           0 :     init_tensor(&amp;t);</span></span>
<span id="L127"><span class="lineNum">     127</span>                 :             :     // allocate new buffers and copy first the dst channels</span>
<span id="L128"><span class="lineNum">     128</span>                 :<span class="tlaUNC">           0 :     if (!realloc_tensor(&amp;t, channels, dst-&gt;width, dst-&gt;height)) return false;</span></span>
<span id="L129"><span class="lineNum">     129</span>                 :<span class="tlaUNC">           0 :     copy_tensor(dst, dst-&gt;channels, 0, &amp;t);</span></span>
<span id="L130"><span class="lineNum">     130</span>                 :             :     // Swap the tensors and free the old buffers</span>
<span id="L131"><span class="lineNum">     131</span>                 :<span class="tlaUNC">           0 :     swap_tensor(dst, &amp;t);</span></span>
<span id="L132"><span class="lineNum">     132</span>                 :<span class="tlaUNC">           0 :     free_tensor(&amp;t);</span></span>
<span id="L133"><span class="lineNum">     133</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L134"><span class="lineNum">     134</span>                 :<span class="tlaUNC">           0 :   for (int c = 1; c &lt; channels; ++c)</span></span>
<span id="L135"><span class="lineNum">     135</span>                 :<span class="tlaUNC">           0 :     dst-&gt;buf[c] = &amp;dst-&gt;buf[0][c * dst-&gt;width * dst-&gt;height];</span></span>
<span id="L136"><span class="lineNum">     136</span>                 :             :   // Copy the channels in src after the first dst_channels channels.</span>
<span id="L137"><span class="lineNum">     137</span>                 :<span class="tlaUNC">           0 :   copy_tensor(src, src-&gt;channels, dst_channels, dst);</span></span>
<span id="L138"><span class="lineNum">     138</span>                 :<span class="tlaUNC">           0 :   return true;</span></span>
<span id="L139"><span class="lineNum">     139</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L140"><span class="lineNum">     140</span>                 :             : </span>
<span id="L141"><span class="lineNum">     141</span>                 :             : #ifndef NDEBUG</span>
<span id="L142"><span class="lineNum">     142</span>                 :             : static int check_tensor_equal_dims(TENSOR *t1, TENSOR *t2) {</span>
<span id="L143"><span class="lineNum">     143</span>                 :             :   return (t1-&gt;width == t2-&gt;width &amp;&amp; t1-&gt;height == t2-&gt;height);</span>
<span id="L144"><span class="lineNum">     144</span>                 :             : }</span>
<span id="L145"><span class="lineNum">     145</span>                 :             : </span>
<span id="L146"><span class="lineNum">     146</span>                 :             : static int check_tensor_equal_size(TENSOR *t1, TENSOR *t2) {</span>
<span id="L147"><span class="lineNum">     147</span>                 :             :   return (t1-&gt;channels == t2-&gt;channels &amp;&amp; t1-&gt;width == t2-&gt;width &amp;&amp;</span>
<span id="L148"><span class="lineNum">     148</span>                 :             :           t1-&gt;height == t2-&gt;height);</span>
<span id="L149"><span class="lineNum">     149</span>                 :             : }</span>
<span id="L150"><span class="lineNum">     150</span>                 :             : #endif  // NDEBUG</span>
<span id="L151"><span class="lineNum">     151</span>                 :             : </span>
<span id="L152"><span class="lineNum">     152</span>                 :<span class="tlaUNC">           0 : void av1_find_cnn_layer_output_size(int in_width, int in_height,</span></span>
<span id="L153"><span class="lineNum">     153</span>                 :             :                                     const CNN_LAYER_CONFIG *layer_config,</span>
<span id="L154"><span class="lineNum">     154</span>                 :             :                                     int *out_width, int *out_height) {</span>
<span id="L155"><span class="lineNum">     155</span>                 :             :   assert(layer_config-&gt;skip_width &gt; 0);</span>
<span id="L156"><span class="lineNum">     156</span>                 :             :   assert(layer_config-&gt;skip_height &gt; 0);</span>
<span id="L157"><span class="lineNum">     157</span>                 :<span class="tlaUNC">           0 :   if (!layer_config-&gt;deconvolve) {</span></span>
<span id="L158"><span class="lineNum">     158</span>                 :<span class="tlaUNC">           0 :     switch (layer_config-&gt;pad) {</span></span>
<span id="L159"><span class="lineNum">     159</span>                 :             :       case PADDING_SAME_ZERO:</span>
<span id="L160"><span class="lineNum">     160</span>                 :             :       case PADDING_SAME_REPLICATE:</span>
<span id="L161"><span class="lineNum">     161</span>                 :<span class="tlaUNC">           0 :         *out_width = (in_width + layer_config-&gt;skip_width - 1) /</span></span>
<span id="L162"><span class="lineNum">     162</span>                 :<span class="tlaUNC">           0 :                      layer_config-&gt;skip_width;</span></span>
<span id="L163"><span class="lineNum">     163</span>                 :<span class="tlaUNC">           0 :         *out_height = (in_height + layer_config-&gt;skip_height - 1) /</span></span>
<span id="L164"><span class="lineNum">     164</span>                 :<span class="tlaUNC">           0 :                       layer_config-&gt;skip_height;</span></span>
<span id="L165"><span class="lineNum">     165</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L166"><span class="lineNum">     166</span>                 :             :       case PADDING_VALID:</span>
<span id="L167"><span class="lineNum">     167</span>                 :<span class="tlaUNC">           0 :         *out_width =</span></span>
<span id="L168"><span class="lineNum">     168</span>                 :<span class="tlaUNC">           0 :             (in_width - layer_config-&gt;filter_width + layer_config-&gt;skip_width) /</span></span>
<span id="L169"><span class="lineNum">     169</span>                 :<span class="tlaUNC">           0 :             layer_config-&gt;skip_width;</span></span>
<span id="L170"><span class="lineNum">     170</span>                 :<span class="tlaUNC">           0 :         *out_height = (in_height - layer_config-&gt;filter_height +</span></span>
<span id="L171"><span class="lineNum">     171</span>                 :<span class="tlaUNC">           0 :                        layer_config-&gt;skip_height) /</span></span>
<span id="L172"><span class="lineNum">     172</span>                 :<span class="tlaUNC">           0 :                       layer_config-&gt;skip_height;</span></span>
<span id="L173"><span class="lineNum">     173</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L174"><span class="lineNum">     174</span>                 :             :       default: assert(0 &amp;&amp; &quot;Unknown padding type&quot;);</span>
<span id="L175"><span class="lineNum">     175</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L176"><span class="lineNum">     176</span>                 :<span class="tlaUNC">           0 :   } else {</span></span>
<span id="L177"><span class="lineNum">     177</span>                 :<span class="tlaUNC">           0 :     switch (layer_config-&gt;pad) {</span></span>
<span id="L178"><span class="lineNum">     178</span>                 :             :       case PADDING_SAME_ZERO:</span>
<span id="L179"><span class="lineNum">     179</span>                 :             :       case PADDING_SAME_REPLICATE:</span>
<span id="L180"><span class="lineNum">     180</span>                 :<span class="tlaUNC">           0 :         *out_width = in_width * layer_config-&gt;skip_width;</span></span>
<span id="L181"><span class="lineNum">     181</span>                 :<span class="tlaUNC">           0 :         *out_height = in_height * layer_config-&gt;skip_height;</span></span>
<span id="L182"><span class="lineNum">     182</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L183"><span class="lineNum">     183</span>                 :             :       case PADDING_VALID:</span>
<span id="L184"><span class="lineNum">     184</span>                 :<span class="tlaUNC">           0 :         *out_width = (in_width - 1) * layer_config-&gt;skip_width +</span></span>
<span id="L185"><span class="lineNum">     185</span>                 :<span class="tlaUNC">           0 :                      layer_config-&gt;filter_width;</span></span>
<span id="L186"><span class="lineNum">     186</span>                 :<span class="tlaUNC">           0 :         *out_height = (in_height - 1) * layer_config-&gt;skip_height +</span></span>
<span id="L187"><span class="lineNum">     187</span>                 :<span class="tlaUNC">           0 :                       layer_config-&gt;filter_height;</span></span>
<span id="L188"><span class="lineNum">     188</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L189"><span class="lineNum">     189</span>                 :             :       default: assert(0 &amp;&amp; &quot;Unknown padding type&quot;);</span>
<span id="L190"><span class="lineNum">     190</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L191"><span class="lineNum">     191</span>                 :             :   }</span>
<span id="L192"><span class="lineNum">     192</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L193"><span class="lineNum">     193</span>                 :             : </span>
<span id="L194"><span class="lineNum">     194</span>                 :<span class="tlaUNC">           0 : static void find_cnn_out_channels(const CNN_LAYER_CONFIG *layer_config,</span></span>
<span id="L195"><span class="lineNum">     195</span>                 :             :                                   int channels_per_branch[]) {</span>
<span id="L196"><span class="lineNum">     196</span>                 :<span class="tlaUNC">           0 :   int branch = layer_config-&gt;branch;</span></span>
<span id="L197"><span class="lineNum">     197</span>                 :<span class="tlaUNC">           0 :   const CNN_BRANCH_CONFIG *branch_config = &amp;layer_config-&gt;branch_config;</span></span>
<span id="L198"><span class="lineNum">     198</span>                 :<span class="tlaUNC">           0 :   for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L199"><span class="lineNum">     199</span>                 :<span class="tlaUNC">           0 :     if ((branch_config-&gt;input_to_branches &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L200"><span class="lineNum">     200</span>                 :<span class="tlaUNC">           0 :       if (layer_config-&gt;branch_copy_type == BRANCH_INPUT) {</span></span>
<span id="L201"><span class="lineNum">     201</span>                 :<span class="tlaUNC">           0 :         channels_per_branch[b] = layer_config-&gt;in_channels;</span></span>
<span id="L202"><span class="lineNum">     202</span>                 :<span class="tlaUNC">           0 :       } else if (layer_config-&gt;branch_copy_type == BRANCH_OUTPUT) {</span></span>
<span id="L203"><span class="lineNum">     203</span>                 :<span class="tlaUNC">           0 :         channels_per_branch[b] = layer_config-&gt;out_channels;</span></span>
<span id="L204"><span class="lineNum">     204</span>                 :<span class="tlaUNC">           0 :       } else if (layer_config-&gt;branch_copy_type == BRANCH_COMBINED) {</span></span>
<span id="L205"><span class="lineNum">     205</span>                 :<span class="tlaUNC">           0 :         channels_per_branch[b] = layer_config-&gt;out_channels;</span></span>
<span id="L206"><span class="lineNum">     206</span>                 :<span class="tlaUNC">           0 :         for (int c = 0; c &lt; CNN_MAX_BRANCHES; ++c) {</span></span>
<span id="L207"><span class="lineNum">     207</span>                 :<span class="tlaUNC">           0 :           if ((branch_config-&gt;branches_to_combine &amp; (1 &lt;&lt; c)) &amp;&amp; c != branch) {</span></span>
<span id="L208"><span class="lineNum">     208</span>                 :             :             assert(channels_per_branch[c] &gt; 0);</span>
<span id="L209"><span class="lineNum">     209</span>                 :<span class="tlaUNC">           0 :             channels_per_branch[b] += channels_per_branch[c];</span></span>
<span id="L210"><span class="lineNum">     210</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L211"><span class="lineNum">     211</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L212"><span class="lineNum">     212</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L213"><span class="lineNum">     213</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L214"><span class="lineNum">     214</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L215"><span class="lineNum">     215</span>                 :<span class="tlaUNC">           0 :   channels_per_branch[branch] = layer_config-&gt;out_channels;</span></span>
<span id="L216"><span class="lineNum">     216</span>                 :<span class="tlaUNC">           0 :   for (int c = 0; c &lt; CNN_MAX_BRANCHES; ++c) {</span></span>
<span id="L217"><span class="lineNum">     217</span>                 :<span class="tlaUNC">           0 :     if ((branch_config-&gt;branches_to_combine &amp; (1 &lt;&lt; c)) &amp;&amp; c != branch) {</span></span>
<span id="L218"><span class="lineNum">     218</span>                 :             :       assert(channels_per_branch[c] &gt; 0);</span>
<span id="L219"><span class="lineNum">     219</span>                 :<span class="tlaUNC">           0 :       channels_per_branch[branch] += channels_per_branch[c];</span></span>
<span id="L220"><span class="lineNum">     220</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L221"><span class="lineNum">     221</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L222"><span class="lineNum">     222</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L223"><span class="lineNum">     223</span>                 :             : </span>
<span id="L224"><span class="lineNum">     224</span>                 :             : #if CONFIG_DEBUG</span>
<span id="L225"><span class="lineNum">     225</span>                 :             : static inline int cnn_has_at_least_one_output(const CNN_CONFIG *cnn_config) {</span>
<span id="L226"><span class="lineNum">     226</span>                 :             :   const int num_layers = cnn_config-&gt;num_layers;</span>
<span id="L227"><span class="lineNum">     227</span>                 :             :   const CNN_LAYER_CONFIG *layer_configs = cnn_config-&gt;layer_config;</span>
<span id="L228"><span class="lineNum">     228</span>                 :             : </span>
<span id="L229"><span class="lineNum">     229</span>                 :             :   for (int idx = 0; idx &lt; num_layers; idx++) {</span>
<span id="L230"><span class="lineNum">     230</span>                 :             :     if (layer_configs[idx].output_num != -1) {</span>
<span id="L231"><span class="lineNum">     231</span>                 :             :       return 1;</span>
<span id="L232"><span class="lineNum">     232</span>                 :             :     }</span>
<span id="L233"><span class="lineNum">     233</span>                 :             :   }</span>
<span id="L234"><span class="lineNum">     234</span>                 :             :   return 0;</span>
<span id="L235"><span class="lineNum">     235</span>                 :             : }</span>
<span id="L236"><span class="lineNum">     236</span>                 :             : #endif</span>
<span id="L237"><span class="lineNum">     237</span>                 :             : </span>
<span id="L238"><span class="lineNum">     238</span>                 :<span class="tlaUNC">           0 : void av1_find_cnn_output_size(int in_width, int in_height,</span></span>
<span id="L239"><span class="lineNum">     239</span>                 :             :                               const CNN_CONFIG *cnn_config, int *out_width,</span>
<span id="L240"><span class="lineNum">     240</span>                 :             :                               int *out_height, int *out_channels) {</span>
<span id="L241"><span class="lineNum">     241</span>                 :<span class="tlaUNC">           0 :   int channels_per_branch[CNN_MAX_BRANCHES] = { 0 };</span></span>
<span id="L242"><span class="lineNum">     242</span>                 :<span class="tlaUNC">           0 :   int i_width[CNN_MAX_BRANCHES] = { 0 };</span></span>
<span id="L243"><span class="lineNum">     243</span>                 :<span class="tlaUNC">           0 :   int i_height[CNN_MAX_BRANCHES] = { 0 };</span></span>
<span id="L244"><span class="lineNum">     244</span>                 :<span class="tlaUNC">           0 :   i_width[0] = in_width + cnn_config-&gt;ext_width * 2;</span></span>
<span id="L245"><span class="lineNum">     245</span>                 :<span class="tlaUNC">           0 :   i_height[0] = in_height + cnn_config-&gt;ext_height * 2;</span></span>
<span id="L246"><span class="lineNum">     246</span>                 :             : </span>
<span id="L247"><span class="lineNum">     247</span>                 :             : #if CONFIG_DEBUG</span>
<span id="L248"><span class="lineNum">     248</span>                 :             :   assert(cnn_has_at_least_one_output(cnn_config));</span>
<span id="L249"><span class="lineNum">     249</span>                 :             : #endif</span>
<span id="L250"><span class="lineNum">     250</span>                 :             : </span>
<span id="L251"><span class="lineNum">     251</span>                 :<span class="tlaUNC">           0 :   for (int i = 0; i &lt; cnn_config-&gt;num_layers; ++i) {</span></span>
<span id="L252"><span class="lineNum">     252</span>                 :<span class="tlaUNC">           0 :     const CNN_LAYER_CONFIG *layer_config = &amp;cnn_config-&gt;layer_config[i];</span></span>
<span id="L253"><span class="lineNum">     253</span>                 :<span class="tlaUNC">           0 :     const CNN_BRANCH_CONFIG *branch_config = &amp;layer_config-&gt;branch_config;</span></span>
<span id="L254"><span class="lineNum">     254</span>                 :<span class="tlaUNC">           0 :     const int branch = layer_config-&gt;branch;</span></span>
<span id="L255"><span class="lineNum">     255</span>                 :<span class="tlaUNC">           0 :     int o_width = 0, o_height = 0;</span></span>
<span id="L256"><span class="lineNum">     256</span>                 :             : </span>
<span id="L257"><span class="lineNum">     257</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;branch_copy_type == BRANCH_INPUT) {</span></span>
<span id="L258"><span class="lineNum">     258</span>                 :<span class="tlaUNC">           0 :       for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L259"><span class="lineNum">     259</span>                 :<span class="tlaUNC">           0 :         if ((branch_config-&gt;input_to_branches &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L260"><span class="lineNum">     260</span>                 :             :           assert(i_width[branch] &gt; 0 &amp;&amp; i_height[branch] &gt; 0);</span>
<span id="L261"><span class="lineNum">     261</span>                 :<span class="tlaUNC">           0 :           i_width[b] = i_width[branch];</span></span>
<span id="L262"><span class="lineNum">     262</span>                 :<span class="tlaUNC">           0 :           i_height[b] = i_height[branch];</span></span>
<span id="L263"><span class="lineNum">     263</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L264"><span class="lineNum">     264</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L265"><span class="lineNum">     265</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L266"><span class="lineNum">     266</span>                 :             : </span>
<span id="L267"><span class="lineNum">     267</span>                 :<span class="tlaUNC">           0 :     av1_find_cnn_layer_output_size(i_width[branch], i_height[branch],</span></span>
<span id="L268"><span class="lineNum">     268</span>                 :<span class="tlaUNC">           0 :                                    layer_config, &amp;o_width, &amp;o_height);</span></span>
<span id="L269"><span class="lineNum">     269</span>                 :<span class="tlaUNC">           0 :     i_width[branch] = o_width;</span></span>
<span id="L270"><span class="lineNum">     270</span>                 :<span class="tlaUNC">           0 :     i_height[branch] = o_height;</span></span>
<span id="L271"><span class="lineNum">     271</span>                 :             : </span>
<span id="L272"><span class="lineNum">     272</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;branch_copy_type == BRANCH_OUTPUT) {</span></span>
<span id="L273"><span class="lineNum">     273</span>                 :<span class="tlaUNC">           0 :       for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L274"><span class="lineNum">     274</span>                 :<span class="tlaUNC">           0 :         if ((branch_config-&gt;input_to_branches &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L275"><span class="lineNum">     275</span>                 :<span class="tlaUNC">           0 :           i_width[b] = o_width;</span></span>
<span id="L276"><span class="lineNum">     276</span>                 :<span class="tlaUNC">           0 :           i_height[b] = o_height;</span></span>
<span id="L277"><span class="lineNum">     277</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L278"><span class="lineNum">     278</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L279"><span class="lineNum">     279</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L280"><span class="lineNum">     280</span>                 :             : </span>
<span id="L281"><span class="lineNum">     281</span>                 :<span class="tlaUNC">           0 :     find_cnn_out_channels(layer_config, channels_per_branch);</span></span>
<span id="L282"><span class="lineNum">     282</span>                 :             : </span>
<span id="L283"><span class="lineNum">     283</span>                 :<span class="tlaUNC">           0 :     const int output_num = layer_config-&gt;output_num;</span></span>
<span id="L284"><span class="lineNum">     284</span>                 :<span class="tlaUNC">           0 :     if (output_num != -1) {  // Current layer is an output layer</span></span>
<span id="L285"><span class="lineNum">     285</span>                 :<span class="tlaUNC">           0 :       out_width[output_num] = o_width;</span></span>
<span id="L286"><span class="lineNum">     286</span>                 :<span class="tlaUNC">           0 :       out_height[output_num] = o_height;</span></span>
<span id="L287"><span class="lineNum">     287</span>                 :<span class="tlaUNC">           0 :       out_channels[output_num] = channels_per_branch[layer_config-&gt;branch];</span></span>
<span id="L288"><span class="lineNum">     288</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L289"><span class="lineNum">     289</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L290"><span class="lineNum">     290</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L291"><span class="lineNum">     291</span>                 :             : </span>
<span id="L292"><span class="lineNum">     292</span>                 :<span class="tlaUNC">           0 : static inline int get_start_shift_convolve(int width, int filt_width,</span></span>
<span id="L293"><span class="lineNum">     293</span>                 :             :                                            int stride) {</span>
<span id="L294"><span class="lineNum">     294</span>                 :<span class="tlaUNC">           0 :   const int mod = (width % stride);</span></span>
<span id="L295"><span class="lineNum">     295</span>                 :<span class="tlaUNC">           0 :   const int filt_off = (filt_width - 1) / 2;</span></span>
<span id="L296"><span class="lineNum">     296</span>                 :<span class="tlaUNC">           0 :   const int dif = (mod ? mod - 1 : stride - 1);</span></span>
<span id="L297"><span class="lineNum">     297</span>                 :<span class="tlaUNC">           0 :   return AOMMIN((dif + (filt_width % 2)) / 2, filt_off);</span></span>
<span id="L298"><span class="lineNum">     298</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L299"><span class="lineNum">     299</span>                 :             : </span>
<span id="L300"><span class="lineNum">     300</span>                 :<span class="tlaUNC">           0 : void av1_cnn_add_c(float **output, int channels, int width, int height,</span></span>
<span id="L301"><span class="lineNum">     301</span>                 :             :                    int stride, const float **add) {</span>
<span id="L302"><span class="lineNum">     302</span>                 :<span class="tlaUNC">           0 :   for (int c = 0; c &lt; channels; ++c) {</span></span>
<span id="L303"><span class="lineNum">     303</span>                 :<span class="tlaUNC">           0 :     for (int i = 0; i &lt; height; ++i)</span></span>
<span id="L304"><span class="lineNum">     304</span>                 :<span class="tlaUNC">           0 :       for (int j = 0; j &lt; width; ++j)</span></span>
<span id="L305"><span class="lineNum">     305</span>                 :<span class="tlaUNC">           0 :         output[c][i * stride + j] += add[c][i * stride + j];</span></span>
<span id="L306"><span class="lineNum">     306</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L307"><span class="lineNum">     307</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L308"><span class="lineNum">     308</span>                 :             : </span>
<span id="L309"><span class="lineNum">     309</span>                 :<span class="tlaUNC">           0 : void av1_cnn_activate_c(float **output, int channels, int width, int height,</span></span>
<span id="L310"><span class="lineNum">     310</span>                 :             :                         int stride, ACTIVATION layer_activation) {</span>
<span id="L311"><span class="lineNum">     311</span>                 :<span class="tlaUNC">           0 :   if (layer_activation == RELU) {</span></span>
<span id="L312"><span class="lineNum">     312</span>                 :<span class="tlaUNC">           0 :     for (int c = 0; c &lt; channels; ++c) {</span></span>
<span id="L313"><span class="lineNum">     313</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; height; ++i)</span></span>
<span id="L314"><span class="lineNum">     314</span>                 :<span class="tlaUNC">           0 :         for (int j = 0; j &lt; width; ++j)</span></span>
<span id="L315"><span class="lineNum">     315</span>                 :<span class="tlaUNC">           0 :           output[c][i * stride + j] = relu(output[c][i * stride + j]);</span></span>
<span id="L316"><span class="lineNum">     316</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L317"><span class="lineNum">     317</span>                 :<span class="tlaUNC">           0 :   } else if (layer_activation == SOFTSIGN) {</span></span>
<span id="L318"><span class="lineNum">     318</span>                 :<span class="tlaUNC">           0 :     for (int c = 0; c &lt; channels; ++c) {</span></span>
<span id="L319"><span class="lineNum">     319</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; height; ++i)</span></span>
<span id="L320"><span class="lineNum">     320</span>                 :<span class="tlaUNC">           0 :         for (int j = 0; j &lt; width; ++j)</span></span>
<span id="L321"><span class="lineNum">     321</span>                 :<span class="tlaUNC">           0 :           output[c][i * stride + j] = softsign(output[c][i * stride + j]);</span></span>
<span id="L322"><span class="lineNum">     322</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L323"><span class="lineNum">     323</span>                 :<span class="tlaUNC">           0 :   } else if (layer_activation == SIGMOID) {</span></span>
<span id="L324"><span class="lineNum">     324</span>                 :             :     assert(0 &amp;&amp; &quot;Sigmoid has not been supported in CNN.&quot;);  // TO DO</span>
<span id="L325"><span class="lineNum">     325</span>                 :<span class="tlaUNC">           0 :   } else if (layer_activation != NONE) {</span></span>
<span id="L326"><span class="lineNum">     326</span>                 :             :     assert(0 &amp;&amp; &quot;Unknown activation type&quot;);</span>
<span id="L327"><span class="lineNum">     327</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L328"><span class="lineNum">     328</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L329"><span class="lineNum">     329</span>                 :             : </span>
<span id="L330"><span class="lineNum">     330</span>                 :<span class="tlaUNC">           0 : static bool copy_active_tensor_to_branches(const TENSOR *layer_active_tensor,</span></span>
<span id="L331"><span class="lineNum">     331</span>                 :             :                                            const CNN_LAYER_CONFIG *layer_config,</span>
<span id="L332"><span class="lineNum">     332</span>                 :             :                                            int branch, TENSOR branch_output[]) {</span>
<span id="L333"><span class="lineNum">     333</span>                 :<span class="tlaUNC">           0 :   const CNN_BRANCH_CONFIG *branch_config = &amp;layer_config-&gt;branch_config;</span></span>
<span id="L334"><span class="lineNum">     334</span>                 :<span class="tlaUNC">           0 :   for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L335"><span class="lineNum">     335</span>                 :<span class="tlaUNC">           0 :     if ((branch_config-&gt;input_to_branches &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L336"><span class="lineNum">     336</span>                 :             :       // Copy layer's active tensor to output tensor of branch b if set in</span>
<span id="L337"><span class="lineNum">     337</span>                 :             :       // mask. The output becomes the input of the first layer of the branch</span>
<span id="L338"><span class="lineNum">     338</span>                 :             :       // because the layer of the branch is not the first layer.</span>
<span id="L339"><span class="lineNum">     339</span>                 :<span class="tlaUNC">           0 :       int copy_channels = branch_config-&gt;channels_to_copy &gt; 0</span></span>
<span id="L340"><span class="lineNum">     340</span>                 :<span class="tlaUNC">           0 :                               ? branch_config-&gt;channels_to_copy</span></span>
<span id="L341"><span class="lineNum">     341</span>                 :<span class="tlaUNC">           0 :                               : layer_active_tensor-&gt;channels;</span></span>
<span id="L342"><span class="lineNum">     342</span>                 :<span class="tlaUNC">           0 :       if (!realloc_tensor(&amp;branch_output[b], copy_channels,</span></span>
<span id="L343"><span class="lineNum">     343</span>                 :<span class="tlaUNC">           0 :                           layer_active_tensor-&gt;width,</span></span>
<span id="L344"><span class="lineNum">     344</span>                 :<span class="tlaUNC">           0 :                           layer_active_tensor-&gt;height)) {</span></span>
<span id="L345"><span class="lineNum">     345</span>                 :<span class="tlaUNC">           0 :         return false;</span></span>
<span id="L346"><span class="lineNum">     346</span>                 :             :       }</span>
<span id="L347"><span class="lineNum">     347</span>                 :<span class="tlaUNC">           0 :       copy_tensor(layer_active_tensor, copy_channels, 0, &amp;branch_output[b]);</span></span>
<span id="L348"><span class="lineNum">     348</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L349"><span class="lineNum">     349</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L350"><span class="lineNum">     350</span>                 :<span class="tlaUNC">           0 :   return true;</span></span>
<span id="L351"><span class="lineNum">     351</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L352"><span class="lineNum">     352</span>                 :             : </span>
<span id="L353"><span class="lineNum">     353</span>                 :             : // CNNConvolve specific to maxpool set as 1, either skip_width or skip_height</span>
<span id="L354"><span class="lineNum">     354</span>                 :             : // greater than 1 and padding equal to PADDING_SAME_ZERO.</span>
<span id="L355"><span class="lineNum">     355</span>                 :<span class="tlaUNC">           0 : static void convolve_maxpool_padding_zero(</span></span>
<span id="L356"><span class="lineNum">     356</span>                 :             :     const float **input, int in_width, int in_height, int in_stride,</span>
<span id="L357"><span class="lineNum">     357</span>                 :             :     const CNN_LAYER_CONFIG *const layer_config, float **output, int out_stride,</span>
<span id="L358"><span class="lineNum">     358</span>                 :             :     const int cstep, const int filter_width_half,</span>
<span id="L359"><span class="lineNum">     359</span>                 :             :     const int filter_height_half) {</span>
<span id="L360"><span class="lineNum">     360</span>                 :<span class="tlaUNC">           0 :   for (int i = 0; i &lt; layer_config-&gt;out_channels; ++i) {</span></span>
<span id="L361"><span class="lineNum">     361</span>                 :<span class="tlaUNC">           0 :     for (int h = 0, u = 0; h &lt; in_height; h += layer_config-&gt;skip_height, ++u) {</span></span>
<span id="L362"><span class="lineNum">     362</span>                 :<span class="tlaUNC">           0 :       for (int w = 0, v = 0; w &lt; in_width; w += layer_config-&gt;skip_width, ++v) {</span></span>
<span id="L363"><span class="lineNum">     363</span>                 :<span class="tlaUNC">           0 :         for (int hh = h; hh &lt; AOMMIN(in_height, h + layer_config-&gt;skip_height);</span></span>
<span id="L364"><span class="lineNum">     364</span>                 :<span class="tlaUNC">           0 :              ++hh) {</span></span>
<span id="L365"><span class="lineNum">     365</span>                 :<span class="tlaUNC">           0 :           for (int ww = w; ww &lt; AOMMIN(in_width, w + layer_config-&gt;skip_width);</span></span>
<span id="L366"><span class="lineNum">     366</span>                 :<span class="tlaUNC">           0 :                ++ww) {</span></span>
<span id="L367"><span class="lineNum">     367</span>                 :<span class="tlaUNC">           0 :             float sum = layer_config-&gt;bias[i];</span></span>
<span id="L368"><span class="lineNum">     368</span>                 :<span class="tlaUNC">           0 :             for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L369"><span class="lineNum">     369</span>                 :<span class="tlaUNC">           0 :               int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L370"><span class="lineNum">     370</span>                 :<span class="tlaUNC">           0 :               for (int l = 0; l &lt; layer_config-&gt;filter_height; ++l) {</span></span>
<span id="L371"><span class="lineNum">     371</span>                 :<span class="tlaUNC">           0 :                 const int ii = hh + l - filter_height_half;</span></span>
<span id="L372"><span class="lineNum">     372</span>                 :<span class="tlaUNC">           0 :                 for (int m = 0; m &lt; layer_config-&gt;filter_width;</span></span>
<span id="L373"><span class="lineNum">     373</span>                 :<span class="tlaUNC">           0 :                      ++m, off += cstep) {</span></span>
<span id="L374"><span class="lineNum">     374</span>                 :<span class="tlaUNC">           0 :                   const int jj = ww + m - filter_width_half;</span></span>
<span id="L375"><span class="lineNum">     375</span>                 :<span class="tlaUNC">           0 :                   if (ii &lt; 0 || ii &gt;= in_height || jj &lt; 0 || jj &gt;= in_width)</span></span>
<span id="L376"><span class="lineNum">     376</span>                 :<span class="tlaUNC">           0 :                     continue;</span></span>
<span id="L377"><span class="lineNum">     377</span>                 :<span class="tlaUNC">           0 :                   sum += layer_config-&gt;weights[off] *</span></span>
<span id="L378"><span class="lineNum">     378</span>                 :<span class="tlaUNC">           0 :                          input[k][ii * in_stride + jj];</span></span>
<span id="L379"><span class="lineNum">     379</span>                 :<span class="tlaUNC">           0 :                 }</span></span>
<span id="L380"><span class="lineNum">     380</span>                 :<span class="tlaUNC">           0 :               }</span></span>
<span id="L381"><span class="lineNum">     381</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L382"><span class="lineNum">     382</span>                 :<span class="tlaUNC">           0 :             const float a = sum;</span></span>
<span id="L383"><span class="lineNum">     383</span>                 :<span class="tlaUNC">           0 :             if (h == hh &amp;&amp; w == ww)</span></span>
<span id="L384"><span class="lineNum">     384</span>                 :<span class="tlaUNC">           0 :               output[i][u * out_stride + v] = a;</span></span>
<span id="L385"><span class="lineNum">     385</span>                 :             :             else</span>
<span id="L386"><span class="lineNum">     386</span>                 :<span class="tlaUNC">           0 :               output[i][u * out_stride + v] =</span></span>
<span id="L387"><span class="lineNum">     387</span>                 :<span class="tlaUNC">           0 :                   AOMMAX(output[i][u * out_stride + v], a);</span></span>
<span id="L388"><span class="lineNum">     388</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L389"><span class="lineNum">     389</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L390"><span class="lineNum">     390</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L391"><span class="lineNum">     391</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L392"><span class="lineNum">     392</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L393"><span class="lineNum">     393</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L394"><span class="lineNum">     394</span>                 :             : </span>
<span id="L395"><span class="lineNum">     395</span>                 :             : // CNNConvolve specific to maxpool set as 1, either skip_width or skip_height</span>
<span id="L396"><span class="lineNum">     396</span>                 :             : // greater than 1 and padding equal to PADDING_SAME_REPLICATE.</span>
<span id="L397"><span class="lineNum">     397</span>                 :<span class="tlaUNC">           0 : static void convolve_maxpool_padding_replicate(</span></span>
<span id="L398"><span class="lineNum">     398</span>                 :             :     const float **input, int in_width, int in_height, int in_stride,</span>
<span id="L399"><span class="lineNum">     399</span>                 :             :     const CNN_LAYER_CONFIG *const layer_config, float **output, int out_stride,</span>
<span id="L400"><span class="lineNum">     400</span>                 :             :     const int cstep, const int filter_width_half,</span>
<span id="L401"><span class="lineNum">     401</span>                 :             :     const int filter_height_half) {</span>
<span id="L402"><span class="lineNum">     402</span>                 :<span class="tlaUNC">           0 :   for (int i = 0; i &lt; layer_config-&gt;out_channels; ++i) {</span></span>
<span id="L403"><span class="lineNum">     403</span>                 :<span class="tlaUNC">           0 :     for (int h = 0, u = 0; h &lt; in_height; h += layer_config-&gt;skip_height, ++u) {</span></span>
<span id="L404"><span class="lineNum">     404</span>                 :<span class="tlaUNC">           0 :       for (int w = 0, v = 0; w &lt; in_width; w += layer_config-&gt;skip_width, ++v) {</span></span>
<span id="L405"><span class="lineNum">     405</span>                 :<span class="tlaUNC">           0 :         for (int hh = h; hh &lt; AOMMIN(in_height, h + layer_config-&gt;skip_height);</span></span>
<span id="L406"><span class="lineNum">     406</span>                 :<span class="tlaUNC">           0 :              ++hh) {</span></span>
<span id="L407"><span class="lineNum">     407</span>                 :<span class="tlaUNC">           0 :           for (int ww = w; ww &lt; AOMMIN(in_width, w + layer_config-&gt;skip_width);</span></span>
<span id="L408"><span class="lineNum">     408</span>                 :<span class="tlaUNC">           0 :                ++ww) {</span></span>
<span id="L409"><span class="lineNum">     409</span>                 :<span class="tlaUNC">           0 :             float sum = layer_config-&gt;bias[i];</span></span>
<span id="L410"><span class="lineNum">     410</span>                 :<span class="tlaUNC">           0 :             for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L411"><span class="lineNum">     411</span>                 :<span class="tlaUNC">           0 :               int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L412"><span class="lineNum">     412</span>                 :<span class="tlaUNC">           0 :               for (int l = 0; l &lt; layer_config-&gt;filter_height; ++l) {</span></span>
<span id="L413"><span class="lineNum">     413</span>                 :<span class="tlaUNC">           0 :                 const int ii =</span></span>
<span id="L414"><span class="lineNum">     414</span>                 :<span class="tlaUNC">           0 :                     CLAMPINDEX(hh + l - filter_height_half, in_height);</span></span>
<span id="L415"><span class="lineNum">     415</span>                 :<span class="tlaUNC">           0 :                 for (int m = 0; m &lt; layer_config-&gt;filter_width;</span></span>
<span id="L416"><span class="lineNum">     416</span>                 :<span class="tlaUNC">           0 :                      ++m, off += cstep) {</span></span>
<span id="L417"><span class="lineNum">     417</span>                 :<span class="tlaUNC">           0 :                   const int jj =</span></span>
<span id="L418"><span class="lineNum">     418</span>                 :<span class="tlaUNC">           0 :                       CLAMPINDEX(ww + m - filter_width_half, in_width);</span></span>
<span id="L419"><span class="lineNum">     419</span>                 :             :                   assert(ii &gt;= 0 &amp;&amp; ii &lt; in_height &amp;&amp; jj &gt;= 0 &amp;&amp; jj &lt; in_width);</span>
<span id="L420"><span class="lineNum">     420</span>                 :<span class="tlaUNC">           0 :                   sum += layer_config-&gt;weights[off] *</span></span>
<span id="L421"><span class="lineNum">     421</span>                 :<span class="tlaUNC">           0 :                          input[k][ii * in_stride + jj];</span></span>
<span id="L422"><span class="lineNum">     422</span>                 :<span class="tlaUNC">           0 :                 }</span></span>
<span id="L423"><span class="lineNum">     423</span>                 :<span class="tlaUNC">           0 :               }</span></span>
<span id="L424"><span class="lineNum">     424</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L425"><span class="lineNum">     425</span>                 :<span class="tlaUNC">           0 :             const float a = sum;</span></span>
<span id="L426"><span class="lineNum">     426</span>                 :<span class="tlaUNC">           0 :             if (h == hh &amp;&amp; w == ww)</span></span>
<span id="L427"><span class="lineNum">     427</span>                 :<span class="tlaUNC">           0 :               output[i][u * out_stride + v] = a;</span></span>
<span id="L428"><span class="lineNum">     428</span>                 :             :             else</span>
<span id="L429"><span class="lineNum">     429</span>                 :<span class="tlaUNC">           0 :               output[i][u * out_stride + v] =</span></span>
<span id="L430"><span class="lineNum">     430</span>                 :<span class="tlaUNC">           0 :                   AOMMAX(output[i][u * out_stride + v], a);</span></span>
<span id="L431"><span class="lineNum">     431</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L432"><span class="lineNum">     432</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L433"><span class="lineNum">     433</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L434"><span class="lineNum">     434</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L435"><span class="lineNum">     435</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L436"><span class="lineNum">     436</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L437"><span class="lineNum">     437</span>                 :             : </span>
<span id="L438"><span class="lineNum">     438</span>                 :             : // CNNConvolve specific to maxpool set as 1, either skip_width or skip_height</span>
<span id="L439"><span class="lineNum">     439</span>                 :             : // greater than 1 and padding equal to PADDING_VALID.</span>
<span id="L440"><span class="lineNum">     440</span>                 :<span class="tlaUNC">           0 : static void convolve_maxpool_padding_valid(</span></span>
<span id="L441"><span class="lineNum">     441</span>                 :             :     const float **input, int in_width, int in_height, int in_stride,</span>
<span id="L442"><span class="lineNum">     442</span>                 :             :     const CNN_LAYER_CONFIG *const layer_config, float **output, int out_stride,</span>
<span id="L443"><span class="lineNum">     443</span>                 :             :     const int cstep) {</span>
<span id="L444"><span class="lineNum">     444</span>                 :<span class="tlaUNC">           0 :   for (int i = 0; i &lt; layer_config-&gt;out_channels; ++i) {</span></span>
<span id="L445"><span class="lineNum">     445</span>                 :<span class="tlaUNC">           0 :     for (int h = 0, u = 0; h &lt; in_height - layer_config-&gt;filter_height + 1;</span></span>
<span id="L446"><span class="lineNum">     446</span>                 :<span class="tlaUNC">           0 :          h += layer_config-&gt;skip_height, ++u) {</span></span>
<span id="L447"><span class="lineNum">     447</span>                 :<span class="tlaUNC">           0 :       for (int w = 0, v = 0; w &lt; in_width - layer_config-&gt;filter_width + 1;</span></span>
<span id="L448"><span class="lineNum">     448</span>                 :<span class="tlaUNC">           0 :            w += layer_config-&gt;skip_width, ++v) {</span></span>
<span id="L449"><span class="lineNum">     449</span>                 :<span class="tlaUNC">           0 :         for (int hh = h; hh &lt; AOMMIN(in_height, h + layer_config-&gt;skip_height);</span></span>
<span id="L450"><span class="lineNum">     450</span>                 :<span class="tlaUNC">           0 :              ++hh) {</span></span>
<span id="L451"><span class="lineNum">     451</span>                 :<span class="tlaUNC">           0 :           for (int ww = w; ww &lt; AOMMIN(in_width, w + layer_config-&gt;skip_width);</span></span>
<span id="L452"><span class="lineNum">     452</span>                 :<span class="tlaUNC">           0 :                ++ww) {</span></span>
<span id="L453"><span class="lineNum">     453</span>                 :<span class="tlaUNC">           0 :             float sum = layer_config-&gt;bias[i];</span></span>
<span id="L454"><span class="lineNum">     454</span>                 :<span class="tlaUNC">           0 :             for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L455"><span class="lineNum">     455</span>                 :<span class="tlaUNC">           0 :               int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L456"><span class="lineNum">     456</span>                 :<span class="tlaUNC">           0 :               for (int l = 0; l &lt; layer_config-&gt;filter_height; ++l) {</span></span>
<span id="L457"><span class="lineNum">     457</span>                 :<span class="tlaUNC">           0 :                 const int ii = hh + l;</span></span>
<span id="L458"><span class="lineNum">     458</span>                 :<span class="tlaUNC">           0 :                 for (int m = 0; m &lt; layer_config-&gt;filter_width;</span></span>
<span id="L459"><span class="lineNum">     459</span>                 :<span class="tlaUNC">           0 :                      ++m, off += cstep) {</span></span>
<span id="L460"><span class="lineNum">     460</span>                 :<span class="tlaUNC">           0 :                   const int jj = ww + m;</span></span>
<span id="L461"><span class="lineNum">     461</span>                 :             :                   assert(ii &gt;= 0 &amp;&amp; ii &lt; in_height &amp;&amp; jj &gt;= 0 &amp;&amp; jj &lt; in_width);</span>
<span id="L462"><span class="lineNum">     462</span>                 :<span class="tlaUNC">           0 :                   sum += layer_config-&gt;weights[off] *</span></span>
<span id="L463"><span class="lineNum">     463</span>                 :<span class="tlaUNC">           0 :                          input[k][ii * in_stride + jj];</span></span>
<span id="L464"><span class="lineNum">     464</span>                 :<span class="tlaUNC">           0 :                 }</span></span>
<span id="L465"><span class="lineNum">     465</span>                 :<span class="tlaUNC">           0 :               }</span></span>
<span id="L466"><span class="lineNum">     466</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L467"><span class="lineNum">     467</span>                 :<span class="tlaUNC">           0 :             const float a = sum;</span></span>
<span id="L468"><span class="lineNum">     468</span>                 :<span class="tlaUNC">           0 :             if (h == hh &amp;&amp; w == ww)</span></span>
<span id="L469"><span class="lineNum">     469</span>                 :<span class="tlaUNC">           0 :               output[i][u * out_stride + v] = a;</span></span>
<span id="L470"><span class="lineNum">     470</span>                 :             :             else</span>
<span id="L471"><span class="lineNum">     471</span>                 :<span class="tlaUNC">           0 :               output[i][u * out_stride + v] =</span></span>
<span id="L472"><span class="lineNum">     472</span>                 :<span class="tlaUNC">           0 :                   AOMMAX(output[i][u * out_stride + v], a);</span></span>
<span id="L473"><span class="lineNum">     473</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L474"><span class="lineNum">     474</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L475"><span class="lineNum">     475</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L476"><span class="lineNum">     476</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L477"><span class="lineNum">     477</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L478"><span class="lineNum">     478</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L479"><span class="lineNum">     479</span>                 :             : </span>
<span id="L480"><span class="lineNum">     480</span>                 :             : // CNNConvolve specific to maxpool set as 0 with filter_height and filter_width</span>
<span id="L481"><span class="lineNum">     481</span>                 :             : // equal to 1.</span>
<span id="L482"><span class="lineNum">     482</span>                 :<span class="tlaUNC">           0 : static void convolve_element_wise(const float **input, int in_width,</span></span>
<span id="L483"><span class="lineNum">     483</span>                 :             :                                   int in_height, int in_stride,</span>
<span id="L484"><span class="lineNum">     484</span>                 :             :                                   const CNN_LAYER_CONFIG *const layer_config,</span>
<span id="L485"><span class="lineNum">     485</span>                 :             :                                   float **output, int out_stride, int start_idx,</span>
<span id="L486"><span class="lineNum">     486</span>                 :             :                                   int step) {</span>
<span id="L487"><span class="lineNum">     487</span>                 :<span class="tlaUNC">           0 :   const int start_h = get_start_shift_convolve(</span></span>
<span id="L488"><span class="lineNum">     488</span>                 :<span class="tlaUNC">           0 :       in_height, layer_config-&gt;filter_height, layer_config-&gt;skip_height);</span></span>
<span id="L489"><span class="lineNum">     489</span>                 :<span class="tlaUNC">           0 :   const int start_w =</span></span>
<span id="L490"><span class="lineNum">     490</span>                 :<span class="tlaUNC">           0 :       get_start_shift_convolve(in_width, layer_config-&gt;filter_width,</span></span>
<span id="L491"><span class="lineNum">     491</span>                 :<span class="tlaUNC">           0 :                                layer_config-&gt;skip_width) +</span></span>
<span id="L492"><span class="lineNum">     492</span>                 :<span class="tlaUNC">           0 :       start_idx * layer_config-&gt;skip_width;</span></span>
<span id="L493"><span class="lineNum">     493</span>                 :<span class="tlaUNC">           0 :   const int out_w_step = AOMMAX(step, 1);</span></span>
<span id="L494"><span class="lineNum">     494</span>                 :<span class="tlaUNC">           0 :   const int in_w_step = layer_config-&gt;skip_width * out_w_step;</span></span>
<span id="L495"><span class="lineNum">     495</span>                 :<span class="tlaUNC">           0 :   for (int i = 0; i &lt; layer_config-&gt;out_channels; ++i) {</span></span>
<span id="L496"><span class="lineNum">     496</span>                 :<span class="tlaUNC">           0 :     for (int h = start_h, u = 0; h &lt; in_height;</span></span>
<span id="L497"><span class="lineNum">     497</span>                 :<span class="tlaUNC">           0 :          h += layer_config-&gt;skip_height, ++u) {</span></span>
<span id="L498"><span class="lineNum">     498</span>                 :<span class="tlaUNC">           0 :       const int in_h = h * in_stride;</span></span>
<span id="L499"><span class="lineNum">     499</span>                 :<span class="tlaUNC">           0 :       const int out_h = u * out_stride + start_idx;</span></span>
<span id="L500"><span class="lineNum">     500</span>                 :<span class="tlaUNC">           0 :       for (int w = start_w, out_index = out_h; w &lt; in_width;</span></span>
<span id="L501"><span class="lineNum">     501</span>                 :<span class="tlaUNC">           0 :            w += in_w_step, out_index += out_w_step) {</span></span>
<span id="L502"><span class="lineNum">     502</span>                 :<span class="tlaUNC">           0 :         float sum = layer_config-&gt;bias[i];</span></span>
<span id="L503"><span class="lineNum">     503</span>                 :<span class="tlaUNC">           0 :         for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L504"><span class="lineNum">     504</span>                 :<span class="tlaUNC">           0 :           sum += layer_config-&gt;weights[k * layer_config-&gt;out_channels + i] *</span></span>
<span id="L505"><span class="lineNum">     505</span>                 :<span class="tlaUNC">           0 :                  input[k][in_h + w];</span></span>
<span id="L506"><span class="lineNum">     506</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L507"><span class="lineNum">     507</span>                 :<span class="tlaUNC">           0 :         output[i][out_index] = sum;</span></span>
<span id="L508"><span class="lineNum">     508</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L509"><span class="lineNum">     509</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L510"><span class="lineNum">     510</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L511"><span class="lineNum">     511</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L512"><span class="lineNum">     512</span>                 :             : </span>
<span id="L513"><span class="lineNum">     513</span>                 :             : // CNNConvolve specific to maxpool set as 0 and padding equal to</span>
<span id="L514"><span class="lineNum">     514</span>                 :             : // PADDING_SAME_ZERO.</span>
<span id="L515"><span class="lineNum">     515</span>                 :<span class="tlaUNC">           0 : static void convolve_no_maxpool_padding_zero(</span></span>
<span id="L516"><span class="lineNum">     516</span>                 :             :     const float **input, int in_width, int in_height, int in_stride,</span>
<span id="L517"><span class="lineNum">     517</span>                 :             :     const CNN_LAYER_CONFIG *const layer_config, float **output, int out_stride,</span>
<span id="L518"><span class="lineNum">     518</span>                 :             :     int start_idx, const int cstep, const int filter_width_half,</span>
<span id="L519"><span class="lineNum">     519</span>                 :             :     const int filter_height_half, const int ii_shift, const int jj_shift,</span>
<span id="L520"><span class="lineNum">     520</span>                 :             :     const int channel_step) {</span>
<span id="L521"><span class="lineNum">     521</span>                 :<span class="tlaUNC">           0 :   const int start_h = get_start_shift_convolve(</span></span>
<span id="L522"><span class="lineNum">     522</span>                 :<span class="tlaUNC">           0 :       in_height, layer_config-&gt;filter_height, layer_config-&gt;skip_height);</span></span>
<span id="L523"><span class="lineNum">     523</span>                 :<span class="tlaUNC">           0 :   const int start_w = get_start_shift_convolve(</span></span>
<span id="L524"><span class="lineNum">     524</span>                 :<span class="tlaUNC">           0 :       in_width, layer_config-&gt;filter_width, layer_config-&gt;skip_width);</span></span>
<span id="L525"><span class="lineNum">     525</span>                 :<span class="tlaUNC">           0 :   const int end_ii_shift = filter_height_half + 1;</span></span>
<span id="L526"><span class="lineNum">     526</span>                 :<span class="tlaUNC">           0 :   const int end_jj_shift = filter_width_half + 1;</span></span>
<span id="L527"><span class="lineNum">     527</span>                 :             :   // *_filter_margin stores the number of pixels along a dimension in the</span>
<span id="L528"><span class="lineNum">     528</span>                 :             :   // intersection of the complement of the image in the extended image</span>
<span id="L529"><span class="lineNum">     529</span>                 :             :   // and the filter.</span>
<span id="L530"><span class="lineNum">     530</span>                 :<span class="tlaUNC">           0 :   const int top_filter_margin = layer_config-&gt;filter_width * ii_shift;</span></span>
<span id="L531"><span class="lineNum">     531</span>                 :<span class="tlaUNC">           0 :   const int right_filter_margin = end_jj_shift - in_width;</span></span>
<span id="L532"><span class="lineNum">     532</span>                 :<span class="tlaUNC">           0 :   for (int i = start_idx; i &lt; layer_config-&gt;out_channels; i += channel_step) {</span></span>
<span id="L533"><span class="lineNum">     533</span>                 :<span class="tlaUNC">           0 :     for (int h = start_h, u = 0; h &lt; in_height;</span></span>
<span id="L534"><span class="lineNum">     534</span>                 :<span class="tlaUNC">           0 :          h += layer_config-&gt;skip_height, ++u) {</span></span>
<span id="L535"><span class="lineNum">     535</span>                 :<span class="tlaUNC">           0 :       const int out_h = u * out_stride;</span></span>
<span id="L536"><span class="lineNum">     536</span>                 :<span class="tlaUNC">           0 :       const int top_cstep =</span></span>
<span id="L537"><span class="lineNum">     537</span>                 :<span class="tlaUNC">           0 :           AOMMAX(0, top_filter_margin - h * layer_config-&gt;filter_width) *</span></span>
<span id="L538"><span class="lineNum">     538</span>                 :<span class="tlaUNC">           0 :               cstep +</span></span>
<span id="L539"><span class="lineNum">     539</span>                 :<span class="tlaUNC">           0 :           i;</span></span>
<span id="L540"><span class="lineNum">     540</span>                 :<span class="tlaUNC">           0 :       const int start_ii = AOMMAX(0, h - ii_shift);</span></span>
<span id="L541"><span class="lineNum">     541</span>                 :<span class="tlaUNC">           0 :       const int end_ii = AOMMIN(in_height, h + end_ii_shift);</span></span>
<span id="L542"><span class="lineNum">     542</span>                 :<span class="tlaUNC">           0 :       for (int w = start_w, out_index = out_h; w &lt; in_width;</span></span>
<span id="L543"><span class="lineNum">     543</span>                 :<span class="tlaUNC">           0 :            w += layer_config-&gt;skip_width, ++out_index) {</span></span>
<span id="L544"><span class="lineNum">     544</span>                 :<span class="tlaUNC">           0 :         const int left_cstep = AOMMAX(0, jj_shift - w) * cstep;</span></span>
<span id="L545"><span class="lineNum">     545</span>                 :<span class="tlaUNC">           0 :         const int right_cstep = AOMMAX(0, right_filter_margin + w) * cstep;</span></span>
<span id="L546"><span class="lineNum">     546</span>                 :<span class="tlaUNC">           0 :         const int start_jj = AOMMAX(0, w - jj_shift);</span></span>
<span id="L547"><span class="lineNum">     547</span>                 :<span class="tlaUNC">           0 :         const int end_jj = AOMMIN(in_width, w + end_jj_shift);</span></span>
<span id="L548"><span class="lineNum">     548</span>                 :<span class="tlaUNC">           0 :         float sum = layer_config-&gt;bias[i];</span></span>
<span id="L549"><span class="lineNum">     549</span>                 :<span class="tlaUNC">           0 :         for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L550"><span class="lineNum">     550</span>                 :<span class="tlaUNC">           0 :           int off = k * layer_config-&gt;out_channels + top_cstep;</span></span>
<span id="L551"><span class="lineNum">     551</span>                 :<span class="tlaUNC">           0 :           for (int ii = start_ii; ii &lt; end_ii; ++ii) {</span></span>
<span id="L552"><span class="lineNum">     552</span>                 :<span class="tlaUNC">           0 :             off += left_cstep;</span></span>
<span id="L553"><span class="lineNum">     553</span>                 :<span class="tlaUNC">           0 :             for (int jj = start_jj; jj &lt; end_jj; ++jj, off += cstep) {</span></span>
<span id="L554"><span class="lineNum">     554</span>                 :<span class="tlaUNC">           0 :               sum += layer_config-&gt;weights[off] * input[k][ii * in_stride + jj];</span></span>
<span id="L555"><span class="lineNum">     555</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L556"><span class="lineNum">     556</span>                 :<span class="tlaUNC">           0 :             off += right_cstep;</span></span>
<span id="L557"><span class="lineNum">     557</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L558"><span class="lineNum">     558</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L559"><span class="lineNum">     559</span>                 :<span class="tlaUNC">           0 :         output[i][out_index] = sum;</span></span>
<span id="L560"><span class="lineNum">     560</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L561"><span class="lineNum">     561</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L562"><span class="lineNum">     562</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L563"><span class="lineNum">     563</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L564"><span class="lineNum">     564</span>                 :             : </span>
<span id="L565"><span class="lineNum">     565</span>                 :             : // CNNConvolve specific to maxpool set as 0 and padding equal to</span>
<span id="L566"><span class="lineNum">     566</span>                 :             : // PADDING_SAME_REPLICATE.</span>
<span id="L567"><span class="lineNum">     567</span>                 :<span class="tlaUNC">           0 : static void convolve_no_maxpool_padding_replicate(</span></span>
<span id="L568"><span class="lineNum">     568</span>                 :             :     const float **input, int in_width, int in_height, int in_stride,</span>
<span id="L569"><span class="lineNum">     569</span>                 :             :     const CNN_LAYER_CONFIG *const layer_config, float **output, int out_stride,</span>
<span id="L570"><span class="lineNum">     570</span>                 :             :     int start_idx, const int cstep, const int ii_shift, const int jj_shift,</span>
<span id="L571"><span class="lineNum">     571</span>                 :             :     const int channel_step) {</span>
<span id="L572"><span class="lineNum">     572</span>                 :             :   // h and w are shifted to an offset coordinate system to reduce in-loop</span>
<span id="L573"><span class="lineNum">     573</span>                 :             :   // computation.</span>
<span id="L574"><span class="lineNum">     574</span>                 :<span class="tlaUNC">           0 :   const int start_h =</span></span>
<span id="L575"><span class="lineNum">     575</span>                 :<span class="tlaUNC">           0 :       get_start_shift_convolve(in_height, layer_config-&gt;filter_height,</span></span>
<span id="L576"><span class="lineNum">     576</span>                 :<span class="tlaUNC">           0 :                                layer_config-&gt;skip_height) -</span></span>
<span id="L577"><span class="lineNum">     577</span>                 :<span class="tlaUNC">           0 :       ii_shift;</span></span>
<span id="L578"><span class="lineNum">     578</span>                 :<span class="tlaUNC">           0 :   const int start_w =</span></span>
<span id="L579"><span class="lineNum">     579</span>                 :<span class="tlaUNC">           0 :       get_start_shift_convolve(in_width, layer_config-&gt;filter_width,</span></span>
<span id="L580"><span class="lineNum">     580</span>                 :<span class="tlaUNC">           0 :                                layer_config-&gt;skip_width) -</span></span>
<span id="L581"><span class="lineNum">     581</span>                 :<span class="tlaUNC">           0 :       jj_shift;</span></span>
<span id="L582"><span class="lineNum">     582</span>                 :<span class="tlaUNC">           0 :   const int end_h = in_height - ii_shift;</span></span>
<span id="L583"><span class="lineNum">     583</span>                 :<span class="tlaUNC">           0 :   const int end_w = in_width - jj_shift;</span></span>
<span id="L584"><span class="lineNum">     584</span>                 :<span class="tlaUNC">           0 :   for (int i = start_idx; i &lt; layer_config-&gt;out_channels; i += channel_step) {</span></span>
<span id="L585"><span class="lineNum">     585</span>                 :<span class="tlaUNC">           0 :     for (int h = start_h, u = 0; h &lt; end_h;</span></span>
<span id="L586"><span class="lineNum">     586</span>                 :<span class="tlaUNC">           0 :          h += layer_config-&gt;skip_height, ++u) {</span></span>
<span id="L587"><span class="lineNum">     587</span>                 :<span class="tlaUNC">           0 :       const int out_h = u * out_stride;</span></span>
<span id="L588"><span class="lineNum">     588</span>                 :<span class="tlaUNC">           0 :       const int upper_ii_index = layer_config-&gt;filter_height + h;</span></span>
<span id="L589"><span class="lineNum">     589</span>                 :<span class="tlaUNC">           0 :       for (int w = start_w, out_index = out_h; w &lt; end_w;</span></span>
<span id="L590"><span class="lineNum">     590</span>                 :<span class="tlaUNC">           0 :            w += layer_config-&gt;skip_width, ++out_index) {</span></span>
<span id="L591"><span class="lineNum">     591</span>                 :<span class="tlaUNC">           0 :         const int upper_jj_index = layer_config-&gt;filter_width + w;</span></span>
<span id="L592"><span class="lineNum">     592</span>                 :<span class="tlaUNC">           0 :         float sum = layer_config-&gt;bias[i];</span></span>
<span id="L593"><span class="lineNum">     593</span>                 :<span class="tlaUNC">           0 :         for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L594"><span class="lineNum">     594</span>                 :<span class="tlaUNC">           0 :           int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L595"><span class="lineNum">     595</span>                 :<span class="tlaUNC">           0 :           for (int ii = h; ii &lt; upper_ii_index; ++ii) {</span></span>
<span id="L596"><span class="lineNum">     596</span>                 :<span class="tlaUNC">           0 :             const int clamped_ii = CLAMPINDEX(ii, in_height);</span></span>
<span id="L597"><span class="lineNum">     597</span>                 :<span class="tlaUNC">           0 :             for (int jj = w; jj &lt; upper_jj_index; ++jj) {</span></span>
<span id="L598"><span class="lineNum">     598</span>                 :<span class="tlaUNC">           0 :               const int clamped_jj = CLAMPINDEX(jj, in_width);</span></span>
<span id="L599"><span class="lineNum">     599</span>                 :             :               assert(clamped_ii &gt;= 0 &amp;&amp; clamped_ii &lt; in_height &amp;&amp;</span>
<span id="L600"><span class="lineNum">     600</span>                 :             :                      clamped_jj &gt;= 0 &amp;&amp; clamped_jj &lt; in_width);</span>
<span id="L601"><span class="lineNum">     601</span>                 :<span class="tlaUNC">           0 :               sum += layer_config-&gt;weights[off] *</span></span>
<span id="L602"><span class="lineNum">     602</span>                 :<span class="tlaUNC">           0 :                      input[k][clamped_ii * in_stride + clamped_jj];</span></span>
<span id="L603"><span class="lineNum">     603</span>                 :<span class="tlaUNC">           0 :               off += cstep;</span></span>
<span id="L604"><span class="lineNum">     604</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L605"><span class="lineNum">     605</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L606"><span class="lineNum">     606</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L607"><span class="lineNum">     607</span>                 :<span class="tlaUNC">           0 :         output[i][out_index] = sum;</span></span>
<span id="L608"><span class="lineNum">     608</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L609"><span class="lineNum">     609</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L610"><span class="lineNum">     610</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L611"><span class="lineNum">     611</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L612"><span class="lineNum">     612</span>                 :             : </span>
<span id="L613"><span class="lineNum">     613</span>                 :             : // CNNConvolve specific to maxpool set as 0 and padding equal to</span>
<span id="L614"><span class="lineNum">     614</span>                 :             : // PADDING_VALID.</span>
<span id="L615"><span class="lineNum">     615</span>                 :<span class="tlaUNC">           0 : void av1_cnn_convolve_no_maxpool_padding_valid_c(</span></span>
<span id="L616"><span class="lineNum">     616</span>                 :             :     const float **input, int in_width, int in_height, int in_stride,</span>
<span id="L617"><span class="lineNum">     617</span>                 :             :     const CNN_LAYER_CONFIG *layer_config, float **output, int out_stride,</span>
<span id="L618"><span class="lineNum">     618</span>                 :             :     int start_idx, int cstep, int channel_step) {</span>
<span id="L619"><span class="lineNum">     619</span>                 :             :   assert((layer_config-&gt;skip_height == 1 &amp;&amp; layer_config-&gt;skip_width == 1) ||</span>
<span id="L620"><span class="lineNum">     620</span>                 :             :          !layer_config-&gt;maxpool);</span>
<span id="L621"><span class="lineNum">     621</span>                 :             :   assert(layer_config-&gt;filter_height &gt; 1 || layer_config-&gt;filter_width &gt; 1);</span>
<span id="L622"><span class="lineNum">     622</span>                 :             :   assert(layer_config-&gt;pad == PADDING_VALID);</span>
<span id="L623"><span class="lineNum">     623</span>                 :<span class="tlaUNC">           0 :   for (int i = start_idx; i &lt; layer_config-&gt;out_channels; i += channel_step) {</span></span>
<span id="L624"><span class="lineNum">     624</span>                 :<span class="tlaUNC">           0 :     for (int h = 0, u = 0; h &lt; in_height - layer_config-&gt;filter_height + 1;</span></span>
<span id="L625"><span class="lineNum">     625</span>                 :<span class="tlaUNC">           0 :          h += layer_config-&gt;skip_height, ++u) {</span></span>
<span id="L626"><span class="lineNum">     626</span>                 :<span class="tlaUNC">           0 :       const int out_h = u * out_stride;</span></span>
<span id="L627"><span class="lineNum">     627</span>                 :<span class="tlaUNC">           0 :       const int upper_ii_index = layer_config-&gt;filter_height + h;</span></span>
<span id="L628"><span class="lineNum">     628</span>                 :<span class="tlaUNC">           0 :       for (int w = 0, out_index = out_h;</span></span>
<span id="L629"><span class="lineNum">     629</span>                 :<span class="tlaUNC">           0 :            w &lt; in_width - layer_config-&gt;filter_width + 1;</span></span>
<span id="L630"><span class="lineNum">     630</span>                 :<span class="tlaUNC">           0 :            w += layer_config-&gt;skip_width, ++out_index) {</span></span>
<span id="L631"><span class="lineNum">     631</span>                 :<span class="tlaUNC">           0 :         const int upper_jj_index = layer_config-&gt;filter_width + w;</span></span>
<span id="L632"><span class="lineNum">     632</span>                 :<span class="tlaUNC">           0 :         float sum = layer_config-&gt;bias[i];</span></span>
<span id="L633"><span class="lineNum">     633</span>                 :<span class="tlaUNC">           0 :         for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L634"><span class="lineNum">     634</span>                 :<span class="tlaUNC">           0 :           int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L635"><span class="lineNum">     635</span>                 :<span class="tlaUNC">           0 :           for (int ii = h; ii &lt; upper_ii_index; ++ii) {</span></span>
<span id="L636"><span class="lineNum">     636</span>                 :<span class="tlaUNC">           0 :             for (int jj = w; jj &lt; upper_jj_index; ++jj) {</span></span>
<span id="L637"><span class="lineNum">     637</span>                 :             :               assert(ii &gt;= 0 &amp;&amp; ii &lt; in_height &amp;&amp; jj &gt;= 0 &amp;&amp; jj &lt; in_width);</span>
<span id="L638"><span class="lineNum">     638</span>                 :<span class="tlaUNC">           0 :               sum += layer_config-&gt;weights[off] * input[k][ii * in_stride + jj];</span></span>
<span id="L639"><span class="lineNum">     639</span>                 :<span class="tlaUNC">           0 :               off += cstep;</span></span>
<span id="L640"><span class="lineNum">     640</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L641"><span class="lineNum">     641</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L642"><span class="lineNum">     642</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L643"><span class="lineNum">     643</span>                 :<span class="tlaUNC">           0 :         output[i][out_index] = sum;</span></span>
<span id="L644"><span class="lineNum">     644</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L645"><span class="lineNum">     645</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L646"><span class="lineNum">     646</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L647"><span class="lineNum">     647</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L648"><span class="lineNum">     648</span>                 :             : </span>
<span id="L649"><span class="lineNum">     649</span>                 :<span class="tlaUNC">           0 : static void av1_cnn_convolve(const float **input, int in_width, int in_height,</span></span>
<span id="L650"><span class="lineNum">     650</span>                 :             :                              int in_stride,</span>
<span id="L651"><span class="lineNum">     651</span>                 :             :                              const CNN_LAYER_CONFIG *layer_config,</span>
<span id="L652"><span class="lineNum">     652</span>                 :             :                              float **output, int out_stride, int start_idx,</span>
<span id="L653"><span class="lineNum">     653</span>                 :             :                              int step) {</span>
<span id="L654"><span class="lineNum">     654</span>                 :             :   assert(!layer_config-&gt;deconvolve);</span>
<span id="L655"><span class="lineNum">     655</span>                 :<span class="tlaUNC">           0 :   const int cstep = layer_config-&gt;in_channels * layer_config-&gt;out_channels;</span></span>
<span id="L656"><span class="lineNum">     656</span>                 :<span class="tlaUNC">           0 :   const int filter_height_half = layer_config-&gt;filter_height &gt;&gt; 1;</span></span>
<span id="L657"><span class="lineNum">     657</span>                 :<span class="tlaUNC">           0 :   const int filter_width_half = layer_config-&gt;filter_width &gt;&gt; 1;</span></span>
<span id="L658"><span class="lineNum">     658</span>                 :<span class="tlaUNC">           0 :   const int channel_step = AOMMAX(step, 1);</span></span>
<span id="L659"><span class="lineNum">     659</span>                 :             : </span>
<span id="L660"><span class="lineNum">     660</span>                 :<span class="tlaUNC">           0 :   if (layer_config-&gt;maxpool &amp;&amp;</span></span>
<span id="L661"><span class="lineNum">     661</span>                 :<span class="tlaUNC">           0 :       (layer_config-&gt;skip_height &gt; 1 || layer_config-&gt;skip_width &gt; 1)) {</span></span>
<span id="L662"><span class="lineNum">     662</span>                 :<span class="tlaUNC">           0 :     switch (layer_config-&gt;pad) {</span></span>
<span id="L663"><span class="lineNum">     663</span>                 :             :       case PADDING_SAME_ZERO:</span>
<span id="L664"><span class="lineNum">     664</span>                 :<span class="tlaUNC">           0 :         convolve_maxpool_padding_zero(input, in_width, in_height, in_stride,</span></span>
<span id="L665"><span class="lineNum">     665</span>                 :<span class="tlaUNC">           0 :                                       layer_config, output, out_stride, cstep,</span></span>
<span id="L666"><span class="lineNum">     666</span>                 :<span class="tlaUNC">           0 :                                       filter_width_half, filter_height_half);</span></span>
<span id="L667"><span class="lineNum">     667</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L668"><span class="lineNum">     668</span>                 :             :       case PADDING_SAME_REPLICATE:</span>
<span id="L669"><span class="lineNum">     669</span>                 :<span class="tlaUNC">           0 :         convolve_maxpool_padding_replicate(</span></span>
<span id="L670"><span class="lineNum">     670</span>                 :<span class="tlaUNC">           0 :             input, in_width, in_height, in_stride, layer_config, output,</span></span>
<span id="L671"><span class="lineNum">     671</span>                 :<span class="tlaUNC">           0 :             out_stride, cstep, filter_width_half, filter_height_half);</span></span>
<span id="L672"><span class="lineNum">     672</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L673"><span class="lineNum">     673</span>                 :             :       case PADDING_VALID:</span>
<span id="L674"><span class="lineNum">     674</span>                 :<span class="tlaUNC">           0 :         convolve_maxpool_padding_valid(input, in_width, in_height, in_stride,</span></span>
<span id="L675"><span class="lineNum">     675</span>                 :<span class="tlaUNC">           0 :                                        layer_config, output, out_stride, cstep);</span></span>
<span id="L676"><span class="lineNum">     676</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L677"><span class="lineNum">     677</span>                 :             :       default: assert(0 &amp;&amp; &quot;Unknown padding type&quot;);</span>
<span id="L678"><span class="lineNum">     678</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L679"><span class="lineNum">     679</span>                 :<span class="tlaUNC">           0 :   } else {</span></span>
<span id="L680"><span class="lineNum">     680</span>                 :             :     // Results in element-wise matrix multiplication.</span>
<span id="L681"><span class="lineNum">     681</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;filter_height == 1 &amp;&amp; layer_config-&gt;filter_width == 1) {</span></span>
<span id="L682"><span class="lineNum">     682</span>                 :<span class="tlaUNC">           0 :       convolve_element_wise(input, in_width, in_height, in_stride, layer_config,</span></span>
<span id="L683"><span class="lineNum">     683</span>                 :<span class="tlaUNC">           0 :                             output, out_stride, start_idx, step);</span></span>
<span id="L684"><span class="lineNum">     684</span>                 :<span class="tlaUNC">           0 :       return;</span></span>
<span id="L685"><span class="lineNum">     685</span>                 :             :     }</span>
<span id="L686"><span class="lineNum">     686</span>                 :<span class="tlaUNC">           0 :     const int ii_shift =</span></span>
<span id="L687"><span class="lineNum">     687</span>                 :<span class="tlaUNC">           0 :         filter_height_half - (layer_config-&gt;filter_height - 1) % 2;</span></span>
<span id="L688"><span class="lineNum">     688</span>                 :<span class="tlaUNC">           0 :     const int jj_shift =</span></span>
<span id="L689"><span class="lineNum">     689</span>                 :<span class="tlaUNC">           0 :         filter_width_half - (layer_config-&gt;filter_width - 1) % 2;</span></span>
<span id="L690"><span class="lineNum">     690</span>                 :<span class="tlaUNC">           0 :     switch (layer_config-&gt;pad) {</span></span>
<span id="L691"><span class="lineNum">     691</span>                 :             :       case PADDING_SAME_ZERO:</span>
<span id="L692"><span class="lineNum">     692</span>                 :<span class="tlaUNC">           0 :         convolve_no_maxpool_padding_zero(</span></span>
<span id="L693"><span class="lineNum">     693</span>                 :<span class="tlaUNC">           0 :             input, in_width, in_height, in_stride, layer_config, output,</span></span>
<span id="L694"><span class="lineNum">     694</span>                 :<span class="tlaUNC">           0 :             out_stride, start_idx, cstep, filter_width_half, filter_height_half,</span></span>
<span id="L695"><span class="lineNum">     695</span>                 :<span class="tlaUNC">           0 :             ii_shift, jj_shift, channel_step);</span></span>
<span id="L696"><span class="lineNum">     696</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L697"><span class="lineNum">     697</span>                 :             :       case PADDING_SAME_REPLICATE:</span>
<span id="L698"><span class="lineNum">     698</span>                 :<span class="tlaUNC">           0 :         convolve_no_maxpool_padding_replicate(</span></span>
<span id="L699"><span class="lineNum">     699</span>                 :<span class="tlaUNC">           0 :             input, in_width, in_height, in_stride, layer_config, output,</span></span>
<span id="L700"><span class="lineNum">     700</span>                 :<span class="tlaUNC">           0 :             out_stride, start_idx, cstep, ii_shift, jj_shift, channel_step);</span></span>
<span id="L701"><span class="lineNum">     701</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L702"><span class="lineNum">     702</span>                 :             :       case PADDING_VALID:</span>
<span id="L703"><span class="lineNum">     703</span>                 :<span class="tlaUNC">           0 :         av1_cnn_convolve_no_maxpool_padding_valid(</span></span>
<span id="L704"><span class="lineNum">     704</span>                 :<span class="tlaUNC">           0 :             input, in_width, in_height, in_stride, layer_config, output,</span></span>
<span id="L705"><span class="lineNum">     705</span>                 :<span class="tlaUNC">           0 :             out_stride, start_idx, cstep, channel_step);</span></span>
<span id="L706"><span class="lineNum">     706</span>                 :<span class="tlaUNC">           0 :         break;</span></span>
<span id="L707"><span class="lineNum">     707</span>                 :             :       default: assert(0 &amp;&amp; &quot;Unknown padding type&quot;);</span>
<span id="L708"><span class="lineNum">     708</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L709"><span class="lineNum">     709</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L710"><span class="lineNum">     710</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L711"><span class="lineNum">     711</span>                 :             : </span>
<span id="L712"><span class="lineNum">     712</span>                 :<span class="tlaUNC">           0 : static int convolve_layer(void *arg1, void *arg2) {</span></span>
<span id="L713"><span class="lineNum">     713</span>                 :<span class="tlaUNC">           0 :   const CONVOLVE_OPS *convolve_ops = arg1;</span></span>
<span id="L714"><span class="lineNum">     714</span>                 :<span class="tlaUNC">           0 :   (void)arg2;</span></span>
<span id="L715"><span class="lineNum">     715</span>                 :<span class="tlaUNC">           0 :   av1_cnn_convolve(</span></span>
<span id="L716"><span class="lineNum">     716</span>                 :<span class="tlaUNC">           0 :       convolve_ops-&gt;input, convolve_ops-&gt;in_width, convolve_ops-&gt;in_height,</span></span>
<span id="L717"><span class="lineNum">     717</span>                 :<span class="tlaUNC">           0 :       convolve_ops-&gt;in_stride, convolve_ops-&gt;layer_config, convolve_ops-&gt;output,</span></span>
<span id="L718"><span class="lineNum">     718</span>                 :<span class="tlaUNC">           0 :       convolve_ops-&gt;out_stride, convolve_ops-&gt;start_idx, convolve_ops-&gt;th_step);</span></span>
<span id="L719"><span class="lineNum">     719</span>                 :<span class="tlaUNC">           0 :   return 1;</span></span>
<span id="L720"><span class="lineNum">     720</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L721"><span class="lineNum">     721</span>                 :             : </span>
<span id="L722"><span class="lineNum">     722</span>                 :<span class="tlaUNC">           0 : static void convolve_layer_mt(const float **input, int in_width, int in_height,</span></span>
<span id="L723"><span class="lineNum">     723</span>                 :             :                               int in_stride,</span>
<span id="L724"><span class="lineNum">     724</span>                 :             :                               const CNN_LAYER_CONFIG *layer_config,</span>
<span id="L725"><span class="lineNum">     725</span>                 :             :                               const CNN_THREAD_DATA *thread_data,</span>
<span id="L726"><span class="lineNum">     726</span>                 :             :                               float **output, int out_stride) {</span>
<span id="L727"><span class="lineNum">     727</span>                 :<span class="tlaUNC">           0 :   const AVxWorkerInterface *const winterface = aom_get_worker_interface();</span></span>
<span id="L728"><span class="lineNum">     728</span>                 :<span class="tlaUNC">           0 :   const int num_workers = thread_data-&gt;num_workers;</span></span>
<span id="L729"><span class="lineNum">     729</span>                 :             :   assert(thread_data-&gt;workers);</span>
<span id="L730"><span class="lineNum">     730</span>                 :             : </span>
<span id="L731"><span class="lineNum">     731</span>                 :<span class="tlaUNC">           0 :   CONVOLVE_OPS convolve_ops[CNN_MAX_THREADS];</span></span>
<span id="L732"><span class="lineNum">     732</span>                 :<span class="tlaUNC">           0 :   for (int th = 0; th &lt; AOMMIN(num_workers, CNN_MAX_THREADS); ++th) {</span></span>
<span id="L733"><span class="lineNum">     733</span>                 :<span class="tlaUNC">           0 :     AVxWorker *const worker = &amp;thread_data-&gt;workers[th];</span></span>
<span id="L734"><span class="lineNum">     734</span>                 :<span class="tlaUNC">           0 :     winterface-&gt;reset(worker);</span></span>
<span id="L735"><span class="lineNum">     735</span>                 :             : </span>
<span id="L736"><span class="lineNum">     736</span>                 :<span class="tlaUNC">           0 :     CONVOLVE_OPS convolve_op = { input,      in_width,     in_height,</span></span>
<span id="L737"><span class="lineNum">     737</span>                 :<span class="tlaUNC">           0 :                                  in_stride,  layer_config, output,</span></span>
<span id="L738"><span class="lineNum">     738</span>                 :<span class="tlaUNC">           0 :                                  out_stride, th,           num_workers };</span></span>
<span id="L739"><span class="lineNum">     739</span>                 :<span class="tlaUNC">           0 :     convolve_ops[th] = convolve_op;</span></span>
<span id="L740"><span class="lineNum">     740</span>                 :<span class="tlaUNC">           0 :     worker-&gt;hook = convolve_layer;</span></span>
<span id="L741"><span class="lineNum">     741</span>                 :<span class="tlaUNC">           0 :     worker-&gt;data1 = &amp;(convolve_ops[th]);</span></span>
<span id="L742"><span class="lineNum">     742</span>                 :<span class="tlaUNC">           0 :     worker-&gt;data2 = NULL;</span></span>
<span id="L743"><span class="lineNum">     743</span>                 :             : </span>
<span id="L744"><span class="lineNum">     744</span>                 :             :     // Start convolving.</span>
<span id="L745"><span class="lineNum">     745</span>                 :<span class="tlaUNC">           0 :     if (th == num_workers - 1) {</span></span>
<span id="L746"><span class="lineNum">     746</span>                 :<span class="tlaUNC">           0 :       winterface-&gt;execute(worker);</span></span>
<span id="L747"><span class="lineNum">     747</span>                 :<span class="tlaUNC">           0 :     } else {</span></span>
<span id="L748"><span class="lineNum">     748</span>                 :<span class="tlaUNC">           0 :       winterface-&gt;launch(worker);</span></span>
<span id="L749"><span class="lineNum">     749</span>                 :             :     }</span>
<span id="L750"><span class="lineNum">     750</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L751"><span class="lineNum">     751</span>                 :             : </span>
<span id="L752"><span class="lineNum">     752</span>                 :             :   // Wait until all workers have finished.</span>
<span id="L753"><span class="lineNum">     753</span>                 :<span class="tlaUNC">           0 :   for (int th = 0; th &lt; AOMMIN(num_workers, CNN_MAX_THREADS); ++th) {</span></span>
<span id="L754"><span class="lineNum">     754</span>                 :<span class="tlaUNC">           0 :     winterface-&gt;sync(&amp;thread_data-&gt;workers[th]);</span></span>
<span id="L755"><span class="lineNum">     755</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L756"><span class="lineNum">     756</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L757"><span class="lineNum">     757</span>                 :             : </span>
<span id="L758"><span class="lineNum">     758</span>                 :<span class="tlaUNC">           0 : static inline int get_start_shift_deconvolve(int filt_width, int stride) {</span></span>
<span id="L759"><span class="lineNum">     759</span>                 :<span class="tlaUNC">           0 :   const int dif = AOMMAX(filt_width - stride, 0);</span></span>
<span id="L760"><span class="lineNum">     760</span>                 :<span class="tlaUNC">           0 :   return dif / 2;</span></span>
<span id="L761"><span class="lineNum">     761</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L762"><span class="lineNum">     762</span>                 :             : </span>
<span id="L763"><span class="lineNum">     763</span>                 :<span class="tlaUNC">           0 : void av1_cnn_batchnorm_c(float **image, int channels, int width, int height,</span></span>
<span id="L764"><span class="lineNum">     764</span>                 :             :                          int stride, const float *gamma, const float *beta,</span>
<span id="L765"><span class="lineNum">     765</span>                 :             :                          const float *mean, const float *std) {</span>
<span id="L766"><span class="lineNum">     766</span>                 :             :   assert(gamma &amp;&amp; beta &amp;&amp; beta &amp;&amp; std &amp;&amp; &quot;batchnorm has null parameter!&quot;);</span>
<span id="L767"><span class="lineNum">     767</span>                 :<span class="tlaUNC">           0 :   for (int ch = 0; ch &lt; channels; ch++) {</span></span>
<span id="L768"><span class="lineNum">     768</span>                 :<span class="tlaUNC">           0 :     const float ch_gamma = gamma[ch];</span></span>
<span id="L769"><span class="lineNum">     769</span>                 :<span class="tlaUNC">           0 :     const float ch_beta = beta[ch];</span></span>
<span id="L770"><span class="lineNum">     770</span>                 :<span class="tlaUNC">           0 :     const float ch_mean = mean[ch];</span></span>
<span id="L771"><span class="lineNum">     771</span>                 :<span class="tlaUNC">           0 :     const float ch_std = std[ch];</span></span>
<span id="L772"><span class="lineNum">     772</span>                 :<span class="tlaUNC">           0 :     float *image_row = image[ch];</span></span>
<span id="L773"><span class="lineNum">     773</span>                 :             : </span>
<span id="L774"><span class="lineNum">     774</span>                 :<span class="tlaUNC">           0 :     for (int row = 0; row &lt; height; row++) {</span></span>
<span id="L775"><span class="lineNum">     775</span>                 :<span class="tlaUNC">           0 :       for (int col = 0; col &lt; width; col++) {</span></span>
<span id="L776"><span class="lineNum">     776</span>                 :<span class="tlaUNC">           0 :         image_row[col] =</span></span>
<span id="L777"><span class="lineNum">     777</span>                 :<span class="tlaUNC">           0 :             ch_gamma * (image_row[col] - ch_mean) / ch_std + ch_beta;</span></span>
<span id="L778"><span class="lineNum">     778</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L779"><span class="lineNum">     779</span>                 :<span class="tlaUNC">           0 :       image_row += stride;</span></span>
<span id="L780"><span class="lineNum">     780</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L781"><span class="lineNum">     781</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L782"><span class="lineNum">     782</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L783"><span class="lineNum">     783</span>                 :             : </span>
<span id="L784"><span class="lineNum">     784</span>                 :<span class="tlaUNC">           0 : void av1_cnn_deconvolve_c(const float **input, int in_width, int in_height,</span></span>
<span id="L785"><span class="lineNum">     785</span>                 :             :                           int in_stride, const CNN_LAYER_CONFIG *layer_config,</span>
<span id="L786"><span class="lineNum">     786</span>                 :             :                           float **output, int out_stride) {</span>
<span id="L787"><span class="lineNum">     787</span>                 :             :   assert(layer_config-&gt;deconvolve);</span>
<span id="L788"><span class="lineNum">     788</span>                 :             : </span>
<span id="L789"><span class="lineNum">     789</span>                 :<span class="tlaUNC">           0 :   const int cstep = layer_config-&gt;in_channels * layer_config-&gt;out_channels;</span></span>
<span id="L790"><span class="lineNum">     790</span>                 :             : </span>
<span id="L791"><span class="lineNum">     791</span>                 :<span class="tlaUNC">           0 :   int out_width = 0;</span></span>
<span id="L792"><span class="lineNum">     792</span>                 :<span class="tlaUNC">           0 :   int out_height = 0;</span></span>
<span id="L793"><span class="lineNum">     793</span>                 :<span class="tlaUNC">           0 :   av1_find_cnn_layer_output_size(in_width, in_height, layer_config, &amp;out_width,</span></span>
<span id="L794"><span class="lineNum">     794</span>                 :             :                                  &amp;out_height);</span>
<span id="L795"><span class="lineNum">     795</span>                 :<span class="tlaUNC">           0 :   switch (layer_config-&gt;pad) {</span></span>
<span id="L796"><span class="lineNum">     796</span>                 :             :     case PADDING_SAME_ZERO:</span>
<span id="L797"><span class="lineNum">     797</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; layer_config-&gt;out_channels; ++i) {</span></span>
<span id="L798"><span class="lineNum">     798</span>                 :<span class="tlaUNC">           0 :         for (int u = 0; u &lt; out_height; ++u) {</span></span>
<span id="L799"><span class="lineNum">     799</span>                 :<span class="tlaUNC">           0 :           for (int v = 0; v &lt; out_width; ++v) {</span></span>
<span id="L800"><span class="lineNum">     800</span>                 :<span class="tlaUNC">           0 :             float sum = layer_config-&gt;bias[i];</span></span>
<span id="L801"><span class="lineNum">     801</span>                 :<span class="tlaUNC">           0 :             for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L802"><span class="lineNum">     802</span>                 :<span class="tlaUNC">           0 :               int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L803"><span class="lineNum">     803</span>                 :<span class="tlaUNC">           0 :               for (int l = 0; l &lt; layer_config-&gt;filter_height; ++l) {</span></span>
<span id="L804"><span class="lineNum">     804</span>                 :<span class="tlaUNC">           0 :                 const int h =</span></span>
<span id="L805"><span class="lineNum">     805</span>                 :<span class="tlaUNC">           0 :                     u - l +</span></span>
<span id="L806"><span class="lineNum">     806</span>                 :<span class="tlaUNC">           0 :                     get_start_shift_deconvolve(layer_config-&gt;filter_height,</span></span>
<span id="L807"><span class="lineNum">     807</span>                 :<span class="tlaUNC">           0 :                                                layer_config-&gt;skip_height);</span></span>
<span id="L808"><span class="lineNum">     808</span>                 :<span class="tlaUNC">           0 :                 for (int m = 0; m &lt; layer_config-&gt;filter_width;</span></span>
<span id="L809"><span class="lineNum">     809</span>                 :<span class="tlaUNC">           0 :                      ++m, off += cstep) {</span></span>
<span id="L810"><span class="lineNum">     810</span>                 :<span class="tlaUNC">           0 :                   const int w =</span></span>
<span id="L811"><span class="lineNum">     811</span>                 :<span class="tlaUNC">           0 :                       v - m +</span></span>
<span id="L812"><span class="lineNum">     812</span>                 :<span class="tlaUNC">           0 :                       get_start_shift_deconvolve(layer_config-&gt;filter_width,</span></span>
<span id="L813"><span class="lineNum">     813</span>                 :<span class="tlaUNC">           0 :                                                  layer_config-&gt;skip_width);</span></span>
<span id="L814"><span class="lineNum">     814</span>                 :<span class="tlaUNC">           0 :                   if ((h % layer_config-&gt;skip_height) != 0 ||</span></span>
<span id="L815"><span class="lineNum">     815</span>                 :<span class="tlaUNC">           0 :                       (w % layer_config-&gt;skip_width) != 0)</span></span>
<span id="L816"><span class="lineNum">     816</span>                 :<span class="tlaUNC">           0 :                     continue;</span></span>
<span id="L817"><span class="lineNum">     817</span>                 :<span class="tlaUNC">           0 :                   const int ii = h / layer_config-&gt;skip_height;</span></span>
<span id="L818"><span class="lineNum">     818</span>                 :<span class="tlaUNC">           0 :                   const int jj = w / layer_config-&gt;skip_width;</span></span>
<span id="L819"><span class="lineNum">     819</span>                 :<span class="tlaUNC">           0 :                   if (ii &lt; 0 || ii &gt;= in_height || jj &lt; 0 || jj &gt;= in_width)</span></span>
<span id="L820"><span class="lineNum">     820</span>                 :<span class="tlaUNC">           0 :                     continue;</span></span>
<span id="L821"><span class="lineNum">     821</span>                 :<span class="tlaUNC">           0 :                   sum += layer_config-&gt;weights[off] *</span></span>
<span id="L822"><span class="lineNum">     822</span>                 :<span class="tlaUNC">           0 :                          input[k][ii * in_stride + jj];</span></span>
<span id="L823"><span class="lineNum">     823</span>                 :<span class="tlaUNC">           0 :                 }</span></span>
<span id="L824"><span class="lineNum">     824</span>                 :<span class="tlaUNC">           0 :               }</span></span>
<span id="L825"><span class="lineNum">     825</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L826"><span class="lineNum">     826</span>                 :<span class="tlaUNC">           0 :             output[i][u * out_stride + v] = sum;</span></span>
<span id="L827"><span class="lineNum">     827</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L828"><span class="lineNum">     828</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L829"><span class="lineNum">     829</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L830"><span class="lineNum">     830</span>                 :<span class="tlaUNC">           0 :       break;</span></span>
<span id="L831"><span class="lineNum">     831</span>                 :             :     case PADDING_SAME_REPLICATE:</span>
<span id="L832"><span class="lineNum">     832</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; layer_config-&gt;out_channels; ++i) {</span></span>
<span id="L833"><span class="lineNum">     833</span>                 :<span class="tlaUNC">           0 :         for (int u = 0; u &lt; out_height; ++u) {</span></span>
<span id="L834"><span class="lineNum">     834</span>                 :<span class="tlaUNC">           0 :           for (int v = 0; v &lt; out_width; ++v) {</span></span>
<span id="L835"><span class="lineNum">     835</span>                 :<span class="tlaUNC">           0 :             float sum = layer_config-&gt;bias[i];</span></span>
<span id="L836"><span class="lineNum">     836</span>                 :<span class="tlaUNC">           0 :             for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L837"><span class="lineNum">     837</span>                 :<span class="tlaUNC">           0 :               int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L838"><span class="lineNum">     838</span>                 :<span class="tlaUNC">           0 :               for (int l = 0; l &lt; layer_config-&gt;filter_height; ++l) {</span></span>
<span id="L839"><span class="lineNum">     839</span>                 :<span class="tlaUNC">           0 :                 const int h =</span></span>
<span id="L840"><span class="lineNum">     840</span>                 :<span class="tlaUNC">           0 :                     u - l +</span></span>
<span id="L841"><span class="lineNum">     841</span>                 :<span class="tlaUNC">           0 :                     get_start_shift_deconvolve(layer_config-&gt;filter_height,</span></span>
<span id="L842"><span class="lineNum">     842</span>                 :<span class="tlaUNC">           0 :                                                layer_config-&gt;skip_height);</span></span>
<span id="L843"><span class="lineNum">     843</span>                 :<span class="tlaUNC">           0 :                 for (int m = 0; m &lt; layer_config-&gt;filter_width;</span></span>
<span id="L844"><span class="lineNum">     844</span>                 :<span class="tlaUNC">           0 :                      ++m, off += cstep) {</span></span>
<span id="L845"><span class="lineNum">     845</span>                 :<span class="tlaUNC">           0 :                   const int w =</span></span>
<span id="L846"><span class="lineNum">     846</span>                 :<span class="tlaUNC">           0 :                       v - m +</span></span>
<span id="L847"><span class="lineNum">     847</span>                 :<span class="tlaUNC">           0 :                       get_start_shift_deconvolve(layer_config-&gt;filter_width,</span></span>
<span id="L848"><span class="lineNum">     848</span>                 :<span class="tlaUNC">           0 :                                                  layer_config-&gt;skip_width);</span></span>
<span id="L849"><span class="lineNum">     849</span>                 :<span class="tlaUNC">           0 :                   if ((h % layer_config-&gt;skip_height) != 0 ||</span></span>
<span id="L850"><span class="lineNum">     850</span>                 :<span class="tlaUNC">           0 :                       (w % layer_config-&gt;skip_width) != 0)</span></span>
<span id="L851"><span class="lineNum">     851</span>                 :<span class="tlaUNC">           0 :                     continue;</span></span>
<span id="L852"><span class="lineNum">     852</span>                 :<span class="tlaUNC">           0 :                   const int ii =</span></span>
<span id="L853"><span class="lineNum">     853</span>                 :<span class="tlaUNC">           0 :                       CLAMPINDEX(h / layer_config-&gt;skip_height, in_height);</span></span>
<span id="L854"><span class="lineNum">     854</span>                 :<span class="tlaUNC">           0 :                   const int jj =</span></span>
<span id="L855"><span class="lineNum">     855</span>                 :<span class="tlaUNC">           0 :                       CLAMPINDEX(w / layer_config-&gt;skip_width, in_width);</span></span>
<span id="L856"><span class="lineNum">     856</span>                 :             :                   assert(ii &gt;= 0 &amp;&amp; ii &lt; in_height &amp;&amp; jj &gt;= 0 &amp;&amp; jj &lt; in_width);</span>
<span id="L857"><span class="lineNum">     857</span>                 :<span class="tlaUNC">           0 :                   sum += layer_config-&gt;weights[off] *</span></span>
<span id="L858"><span class="lineNum">     858</span>                 :<span class="tlaUNC">           0 :                          input[k][ii * in_stride + jj];</span></span>
<span id="L859"><span class="lineNum">     859</span>                 :<span class="tlaUNC">           0 :                 }</span></span>
<span id="L860"><span class="lineNum">     860</span>                 :<span class="tlaUNC">           0 :               }</span></span>
<span id="L861"><span class="lineNum">     861</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L862"><span class="lineNum">     862</span>                 :<span class="tlaUNC">           0 :             output[i][u * out_stride + v] = sum;</span></span>
<span id="L863"><span class="lineNum">     863</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L864"><span class="lineNum">     864</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L865"><span class="lineNum">     865</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L866"><span class="lineNum">     866</span>                 :<span class="tlaUNC">           0 :       break;</span></span>
<span id="L867"><span class="lineNum">     867</span>                 :             :     case PADDING_VALID:</span>
<span id="L868"><span class="lineNum">     868</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; layer_config-&gt;out_channels; ++i) {</span></span>
<span id="L869"><span class="lineNum">     869</span>                 :<span class="tlaUNC">           0 :         for (int u = 0; u &lt; out_height; ++u) {</span></span>
<span id="L870"><span class="lineNum">     870</span>                 :<span class="tlaUNC">           0 :           for (int v = 0; v &lt; out_width; ++v) {</span></span>
<span id="L871"><span class="lineNum">     871</span>                 :<span class="tlaUNC">           0 :             float sum = layer_config-&gt;bias[i];</span></span>
<span id="L872"><span class="lineNum">     872</span>                 :<span class="tlaUNC">           0 :             for (int k = 0; k &lt; layer_config-&gt;in_channels; ++k) {</span></span>
<span id="L873"><span class="lineNum">     873</span>                 :<span class="tlaUNC">           0 :               int off = k * layer_config-&gt;out_channels + i;</span></span>
<span id="L874"><span class="lineNum">     874</span>                 :<span class="tlaUNC">           0 :               for (int l = 0; l &lt; layer_config-&gt;filter_height; ++l) {</span></span>
<span id="L875"><span class="lineNum">     875</span>                 :<span class="tlaUNC">           0 :                 const int h = u - l;</span></span>
<span id="L876"><span class="lineNum">     876</span>                 :<span class="tlaUNC">           0 :                 for (int m = 0; m &lt; layer_config-&gt;filter_width;</span></span>
<span id="L877"><span class="lineNum">     877</span>                 :<span class="tlaUNC">           0 :                      ++m, off += cstep) {</span></span>
<span id="L878"><span class="lineNum">     878</span>                 :<span class="tlaUNC">           0 :                   const int w = v - m;</span></span>
<span id="L879"><span class="lineNum">     879</span>                 :<span class="tlaUNC">           0 :                   if ((h % layer_config-&gt;skip_height) != 0 ||</span></span>
<span id="L880"><span class="lineNum">     880</span>                 :<span class="tlaUNC">           0 :                       (w % layer_config-&gt;skip_width) != 0)</span></span>
<span id="L881"><span class="lineNum">     881</span>                 :<span class="tlaUNC">           0 :                     continue;</span></span>
<span id="L882"><span class="lineNum">     882</span>                 :<span class="tlaUNC">           0 :                   const int ii = h / layer_config-&gt;skip_height;</span></span>
<span id="L883"><span class="lineNum">     883</span>                 :<span class="tlaUNC">           0 :                   const int jj = w / layer_config-&gt;skip_width;</span></span>
<span id="L884"><span class="lineNum">     884</span>                 :<span class="tlaUNC">           0 :                   if (ii &lt; 0 || ii &gt;= in_height || jj &lt; 0 || jj &gt;= in_width)</span></span>
<span id="L885"><span class="lineNum">     885</span>                 :<span class="tlaUNC">           0 :                     continue;</span></span>
<span id="L886"><span class="lineNum">     886</span>                 :<span class="tlaUNC">           0 :                   sum += layer_config-&gt;weights[off] *</span></span>
<span id="L887"><span class="lineNum">     887</span>                 :<span class="tlaUNC">           0 :                          input[k][ii * in_stride + jj];</span></span>
<span id="L888"><span class="lineNum">     888</span>                 :<span class="tlaUNC">           0 :                 }</span></span>
<span id="L889"><span class="lineNum">     889</span>                 :<span class="tlaUNC">           0 :               }</span></span>
<span id="L890"><span class="lineNum">     890</span>                 :<span class="tlaUNC">           0 :             }</span></span>
<span id="L891"><span class="lineNum">     891</span>                 :<span class="tlaUNC">           0 :             output[i][u * out_stride + v] = sum;</span></span>
<span id="L892"><span class="lineNum">     892</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L893"><span class="lineNum">     893</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L894"><span class="lineNum">     894</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L895"><span class="lineNum">     895</span>                 :<span class="tlaUNC">           0 :       break;</span></span>
<span id="L896"><span class="lineNum">     896</span>                 :             :     default: assert(0 &amp;&amp; &quot;Unknown padding type&quot;);</span>
<span id="L897"><span class="lineNum">     897</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L898"><span class="lineNum">     898</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L899"><span class="lineNum">     899</span>                 :             : </span>
<span id="L900"><span class="lineNum">     900</span>                 :<span class="tlaUNC">           0 : bool av1_cnn_predict_c(const float **input, int in_width, int in_height,</span></span>
<span id="L901"><span class="lineNum">     901</span>                 :             :                        int in_stride, const CNN_CONFIG *cnn_config,</span>
<span id="L902"><span class="lineNum">     902</span>                 :             :                        const CNN_THREAD_DATA *thread_data,</span>
<span id="L903"><span class="lineNum">     903</span>                 :             :                        CNN_MULTI_OUT *output_struct) {</span>
<span id="L904"><span class="lineNum">     904</span>                 :<span class="tlaUNC">           0 :   bool success = false;</span></span>
<span id="L905"><span class="lineNum">     905</span>                 :<span class="tlaUNC">           0 :   TENSOR tensor1[CNN_MAX_BRANCHES] = { { 0 } };</span></span>
<span id="L906"><span class="lineNum">     906</span>                 :<span class="tlaUNC">           0 :   TENSOR tensor2[CNN_MAX_BRANCHES] = { { 0 } };</span></span>
<span id="L907"><span class="lineNum">     907</span>                 :             : </span>
<span id="L908"><span class="lineNum">     908</span>                 :<span class="tlaUNC">           0 :   float **output[CNN_MAX_BRANCHES];</span></span>
<span id="L909"><span class="lineNum">     909</span>                 :<span class="tlaUNC">           0 :   const int *out_chs = output_struct-&gt;output_channels;</span></span>
<span id="L910"><span class="lineNum">     910</span>                 :<span class="tlaUNC">           0 :   output[0] = output_struct-&gt;output_buffer;</span></span>
<span id="L911"><span class="lineNum">     911</span>                 :<span class="tlaUNC">           0 :   for (int out_idx = 1; out_idx &lt; output_struct-&gt;num_outputs; out_idx++) {</span></span>
<span id="L912"><span class="lineNum">     912</span>                 :<span class="tlaUNC">           0 :     output[out_idx] = output[out_idx - 1] + out_chs[out_idx - 1];</span></span>
<span id="L913"><span class="lineNum">     913</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L914"><span class="lineNum">     914</span>                 :             : </span>
<span id="L915"><span class="lineNum">     915</span>                 :<span class="tlaUNC">           0 :   int i_width = in_width;</span></span>
<span id="L916"><span class="lineNum">     916</span>                 :<span class="tlaUNC">           0 :   int i_height = in_height;</span></span>
<span id="L917"><span class="lineNum">     917</span>                 :<span class="tlaUNC">           0 :   int o_width = 0, o_height = 0;</span></span>
<span id="L918"><span class="lineNum">     918</span>                 :<span class="tlaUNC">           0 :   for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L919"><span class="lineNum">     919</span>                 :<span class="tlaUNC">           0 :     init_tensor(&amp;tensor1[b]);</span></span>
<span id="L920"><span class="lineNum">     920</span>                 :<span class="tlaUNC">           0 :     init_tensor(&amp;tensor2[b]);</span></span>
<span id="L921"><span class="lineNum">     921</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L922"><span class="lineNum">     922</span>                 :             : </span>
<span id="L923"><span class="lineNum">     923</span>                 :<span class="tlaUNC">           0 :   const int *out_stride = output_struct-&gt;output_strides;</span></span>
<span id="L924"><span class="lineNum">     924</span>                 :<span class="tlaUNC">           0 :   for (int layer = 0; layer &lt; cnn_config-&gt;num_layers; ++layer) {</span></span>
<span id="L925"><span class="lineNum">     925</span>                 :<span class="tlaUNC">           0 :     const CNN_LAYER_CONFIG *layer_config = &amp;cnn_config-&gt;layer_config[layer];</span></span>
<span id="L926"><span class="lineNum">     926</span>                 :<span class="tlaUNC">           0 :     const int branch = layer_config-&gt;branch;</span></span>
<span id="L927"><span class="lineNum">     927</span>                 :<span class="tlaUNC">           0 :     const CNN_BRANCH_CONFIG *branch_config = &amp;layer_config-&gt;branch_config;</span></span>
<span id="L928"><span class="lineNum">     928</span>                 :             : </span>
<span id="L929"><span class="lineNum">     929</span>                 :             :     // Allocate input tensor</span>
<span id="L930"><span class="lineNum">     930</span>                 :<span class="tlaUNC">           0 :     if (layer == 0) {       // First layer</span></span>
<span id="L931"><span class="lineNum">     931</span>                 :             :       assert(branch == 0);  // First layer must be primary branch</span>
<span id="L932"><span class="lineNum">     932</span>                 :<span class="tlaUNC">           0 :       assign_tensor(&amp;tensor1[branch], (float **)input,</span></span>
<span id="L933"><span class="lineNum">     933</span>                 :<span class="tlaUNC">           0 :                     layer_config-&gt;in_channels, in_width, in_height, in_stride);</span></span>
<span id="L934"><span class="lineNum">     934</span>                 :<span class="tlaUNC">           0 :     } else {  // Non-first layer</span></span>
<span id="L935"><span class="lineNum">     935</span>                 :             :       // Swap tensor1 and tensor2</span>
<span id="L936"><span class="lineNum">     936</span>                 :<span class="tlaUNC">           0 :       swap_tensor(&amp;tensor1[branch], &amp;tensor2[branch]);</span></span>
<span id="L937"><span class="lineNum">     937</span>                 :             : </span>
<span id="L938"><span class="lineNum">     938</span>                 :<span class="tlaUNC">           0 :       i_width = tensor1[branch].width;</span></span>
<span id="L939"><span class="lineNum">     939</span>                 :<span class="tlaUNC">           0 :       i_height = tensor1[branch].height;</span></span>
<span id="L940"><span class="lineNum">     940</span>                 :             :     }</span>
<span id="L941"><span class="lineNum">     941</span>                 :             : </span>
<span id="L942"><span class="lineNum">     942</span>                 :             :     // Allocate output tensor</span>
<span id="L943"><span class="lineNum">     943</span>                 :<span class="tlaUNC">           0 :     av1_find_cnn_layer_output_size(i_width, i_height, layer_config, &amp;o_width,</span></span>
<span id="L944"><span class="lineNum">     944</span>                 :             :                                    &amp;o_height);</span>
<span id="L945"><span class="lineNum">     945</span>                 :<span class="tlaUNC">           0 :     const int output_num = layer_config-&gt;output_num;</span></span>
<span id="L946"><span class="lineNum">     946</span>                 :<span class="tlaUNC">           0 :     if (output_num == -1) {  // Non-output layer</span></span>
<span id="L947"><span class="lineNum">     947</span>                 :<span class="tlaUNC">           0 :       if (!realloc_tensor(&amp;tensor2[branch], layer_config-&gt;out_channels, o_width,</span></span>
<span id="L948"><span class="lineNum">     948</span>                 :<span class="tlaUNC">           0 :                           o_height)) {</span></span>
<span id="L949"><span class="lineNum">     949</span>                 :<span class="tlaUNC">           0 :         goto Error;</span></span>
<span id="L950"><span class="lineNum">     950</span>                 :             :       }</span>
<span id="L951"><span class="lineNum">     951</span>                 :<span class="tlaUNC">           0 :     } else {  // Output layer</span></span>
<span id="L952"><span class="lineNum">     952</span>                 :<span class="tlaUNC">           0 :       free_tensor(&amp;tensor2[branch]);</span></span>
<span id="L953"><span class="lineNum">     953</span>                 :<span class="tlaUNC">           0 :       assign_tensor(&amp;tensor2[branch], output[output_num],</span></span>
<span id="L954"><span class="lineNum">     954</span>                 :<span class="tlaUNC">           0 :                     layer_config-&gt;out_channels, o_width, o_height,</span></span>
<span id="L955"><span class="lineNum">     955</span>                 :<span class="tlaUNC">           0 :                     out_stride[output_num]);</span></span>
<span id="L956"><span class="lineNum">     956</span>                 :             :     }</span>
<span id="L957"><span class="lineNum">     957</span>                 :             : </span>
<span id="L958"><span class="lineNum">     958</span>                 :             :     // If we are combining branches make sure that the branch to combine</span>
<span id="L959"><span class="lineNum">     959</span>                 :             :     // is different from the current branch.</span>
<span id="L960"><span class="lineNum">     960</span>                 :             :     assert(IMPLIES(layer_config-&gt;branch_combine_type != BRANCH_NOC,</span>
<span id="L961"><span class="lineNum">     961</span>                 :             :                    !(branch_config-&gt;branches_to_combine &amp; (1 &lt;&lt; branch))));</span>
<span id="L962"><span class="lineNum">     962</span>                 :             : </span>
<span id="L963"><span class="lineNum">     963</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;branch_copy_type == BRANCH_INPUT) {</span></span>
<span id="L964"><span class="lineNum">     964</span>                 :<span class="tlaUNC">           0 :       if (!copy_active_tensor_to_branches(&amp;tensor1[branch], layer_config,</span></span>
<span id="L965"><span class="lineNum">     965</span>                 :<span class="tlaUNC">           0 :                                           branch, tensor2)) {</span></span>
<span id="L966"><span class="lineNum">     966</span>                 :<span class="tlaUNC">           0 :         goto Error;</span></span>
<span id="L967"><span class="lineNum">     967</span>                 :             :       }</span>
<span id="L968"><span class="lineNum">     968</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L969"><span class="lineNum">     969</span>                 :             :     // Check consistency of input and output channels</span>
<span id="L970"><span class="lineNum">     970</span>                 :             :     assert(tensor1[branch].channels == layer_config-&gt;in_channels);</span>
<span id="L971"><span class="lineNum">     971</span>                 :             :     assert(tensor2[branch].channels == layer_config-&gt;out_channels);</span>
<span id="L972"><span class="lineNum">     972</span>                 :             : </span>
<span id="L973"><span class="lineNum">     973</span>                 :             :     // Convolve/Deconvolve</span>
<span id="L974"><span class="lineNum">     974</span>                 :<span class="tlaUNC">           0 :     if (!cnn_config-&gt;layer_config[layer].deconvolve) {</span></span>
<span id="L975"><span class="lineNum">     975</span>                 :<span class="tlaUNC">           0 :       if (thread_data-&gt;num_workers &gt; 1) {</span></span>
<span id="L976"><span class="lineNum">     976</span>                 :<span class="tlaUNC">           0 :         convolve_layer_mt((const float **)tensor1[branch].buf,</span></span>
<span id="L977"><span class="lineNum">     977</span>                 :<span class="tlaUNC">           0 :                           tensor1[branch].width, tensor1[branch].height,</span></span>
<span id="L978"><span class="lineNum">     978</span>                 :<span class="tlaUNC">           0 :                           tensor1[branch].stride, layer_config, thread_data,</span></span>
<span id="L979"><span class="lineNum">     979</span>                 :<span class="tlaUNC">           0 :                           tensor2[branch].buf, tensor2[branch].stride);</span></span>
<span id="L980"><span class="lineNum">     980</span>                 :<span class="tlaUNC">           0 :       } else {</span></span>
<span id="L981"><span class="lineNum">     981</span>                 :<span class="tlaUNC">           0 :         av1_cnn_convolve((const float **)tensor1[branch].buf,</span></span>
<span id="L982"><span class="lineNum">     982</span>                 :<span class="tlaUNC">           0 :                          tensor1[branch].width, tensor1[branch].height,</span></span>
<span id="L983"><span class="lineNum">     983</span>                 :<span class="tlaUNC">           0 :                          tensor1[branch].stride, layer_config,</span></span>
<span id="L984"><span class="lineNum">     984</span>                 :<span class="tlaUNC">           0 :                          tensor2[branch].buf, tensor2[branch].stride, 0, 1);</span></span>
<span id="L985"><span class="lineNum">     985</span>                 :             :       }</span>
<span id="L986"><span class="lineNum">     986</span>                 :<span class="tlaUNC">           0 :     } else {</span></span>
<span id="L987"><span class="lineNum">     987</span>                 :<span class="tlaUNC">           0 :       av1_cnn_deconvolve((const float **)tensor1[branch].buf,</span></span>
<span id="L988"><span class="lineNum">     988</span>                 :<span class="tlaUNC">           0 :                          tensor1[branch].width, tensor1[branch].height,</span></span>
<span id="L989"><span class="lineNum">     989</span>                 :<span class="tlaUNC">           0 :                          tensor1[branch].stride, layer_config,</span></span>
<span id="L990"><span class="lineNum">     990</span>                 :<span class="tlaUNC">           0 :                          tensor2[branch].buf, tensor2[branch].stride);</span></span>
<span id="L991"><span class="lineNum">     991</span>                 :             :     }</span>
<span id="L992"><span class="lineNum">     992</span>                 :             : </span>
<span id="L993"><span class="lineNum">     993</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;branch_copy_type == BRANCH_OUTPUT) {</span></span>
<span id="L994"><span class="lineNum">     994</span>                 :<span class="tlaUNC">           0 :       if (!copy_active_tensor_to_branches(&amp;tensor2[branch], layer_config,</span></span>
<span id="L995"><span class="lineNum">     995</span>                 :<span class="tlaUNC">           0 :                                           branch, tensor2)) {</span></span>
<span id="L996"><span class="lineNum">     996</span>                 :<span class="tlaUNC">           0 :         goto Error;</span></span>
<span id="L997"><span class="lineNum">     997</span>                 :             :       }</span>
<span id="L998"><span class="lineNum">     998</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L999"><span class="lineNum">     999</span>                 :             : </span>
<span id="L1000"><span class="lineNum">    1000</span>                 :             :     // Add tensors from other branches if needed</span>
<span id="L1001"><span class="lineNum">    1001</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;branch_combine_type == BRANCH_ADD) {</span></span>
<span id="L1002"><span class="lineNum">    1002</span>                 :<span class="tlaUNC">           0 :       for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L1003"><span class="lineNum">    1003</span>                 :<span class="tlaUNC">           0 :         if ((branch_config-&gt;branches_to_combine &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L1004"><span class="lineNum">    1004</span>                 :             :           assert(check_tensor_equal_size(&amp;tensor2[b], &amp;tensor2[branch]));</span>
<span id="L1005"><span class="lineNum">    1005</span>                 :<span class="tlaUNC">           0 :           av1_cnn_add(tensor2[branch].buf, tensor2[branch].channels,</span></span>
<span id="L1006"><span class="lineNum">    1006</span>                 :<span class="tlaUNC">           0 :                       tensor2[branch].width, tensor2[branch].height,</span></span>
<span id="L1007"><span class="lineNum">    1007</span>                 :<span class="tlaUNC">           0 :                       tensor2[branch].stride, (const float **)tensor2[b].buf);</span></span>
<span id="L1008"><span class="lineNum">    1008</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L1009"><span class="lineNum">    1009</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L1010"><span class="lineNum">    1010</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L1011"><span class="lineNum">    1011</span>                 :             : </span>
<span id="L1012"><span class="lineNum">    1012</span>                 :             :     // Non-linearity</span>
<span id="L1013"><span class="lineNum">    1013</span>                 :<span class="tlaUNC">           0 :     av1_cnn_activate(tensor2[branch].buf, tensor2[branch].channels,</span></span>
<span id="L1014"><span class="lineNum">    1014</span>                 :<span class="tlaUNC">           0 :                      tensor2[branch].width, tensor2[branch].height,</span></span>
<span id="L1015"><span class="lineNum">    1015</span>                 :<span class="tlaUNC">           0 :                      tensor2[branch].stride, layer_config-&gt;activation);</span></span>
<span id="L1016"><span class="lineNum">    1016</span>                 :             : </span>
<span id="L1017"><span class="lineNum">    1017</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;bn_params.bn_gamma) {</span></span>
<span id="L1018"><span class="lineNum">    1018</span>                 :<span class="tlaUNC">           0 :       av1_cnn_batchnorm(</span></span>
<span id="L1019"><span class="lineNum">    1019</span>                 :<span class="tlaUNC">           0 :           tensor2[branch].buf, tensor2[branch].channels, tensor2[branch].width,</span></span>
<span id="L1020"><span class="lineNum">    1020</span>                 :<span class="tlaUNC">           0 :           tensor2[branch].height, tensor2[branch].stride,</span></span>
<span id="L1021"><span class="lineNum">    1021</span>                 :<span class="tlaUNC">           0 :           layer_config-&gt;bn_params.bn_gamma, layer_config-&gt;bn_params.bn_beta,</span></span>
<span id="L1022"><span class="lineNum">    1022</span>                 :<span class="tlaUNC">           0 :           layer_config-&gt;bn_params.bn_mean, layer_config-&gt;bn_params.bn_std);</span></span>
<span id="L1023"><span class="lineNum">    1023</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L1024"><span class="lineNum">    1024</span>                 :             : </span>
<span id="L1025"><span class="lineNum">    1025</span>                 :             :     // Concatenate tensors</span>
<span id="L1026"><span class="lineNum">    1026</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;branch_combine_type == BRANCH_CAT) {</span></span>
<span id="L1027"><span class="lineNum">    1027</span>                 :<span class="tlaUNC">           0 :       if (output_num == -1) {  // Non-output layer</span></span>
<span id="L1028"><span class="lineNum">    1028</span>                 :<span class="tlaUNC">           0 :         for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L1029"><span class="lineNum">    1029</span>                 :<span class="tlaUNC">           0 :           if ((branch_config-&gt;branches_to_combine &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L1030"><span class="lineNum">    1030</span>                 :             :             assert(check_tensor_equal_dims(&amp;tensor2[b], &amp;tensor2[branch]));</span>
<span id="L1031"><span class="lineNum">    1031</span>                 :             :             assert(tensor2[b].channels &gt; 0);</span>
<span id="L1032"><span class="lineNum">    1032</span>                 :<span class="tlaUNC">           0 :             if (!concat_tensor(&amp;tensor2[b], &amp;tensor2[branch])) goto Error;</span></span>
<span id="L1033"><span class="lineNum">    1033</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L1034"><span class="lineNum">    1034</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L1035"><span class="lineNum">    1035</span>                 :<span class="tlaUNC">           0 :       } else {  // Output layer</span></span>
<span id="L1036"><span class="lineNum">    1036</span>                 :<span class="tlaUNC">           0 :         const int existing_channels = tensor2[branch].channels;</span></span>
<span id="L1037"><span class="lineNum">    1037</span>                 :<span class="tlaUNC">           0 :         int num_chs = existing_channels;</span></span>
<span id="L1038"><span class="lineNum">    1038</span>                 :<span class="tlaUNC">           0 :         for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L1039"><span class="lineNum">    1039</span>                 :<span class="tlaUNC">           0 :           if ((branch_config-&gt;branches_to_combine &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L1040"><span class="lineNum">    1040</span>                 :             :             assert(check_tensor_equal_dims(&amp;tensor2[b], &amp;tensor2[branch]));</span>
<span id="L1041"><span class="lineNum">    1041</span>                 :             :             // Needed only to assign the new channel buffers</span>
<span id="L1042"><span class="lineNum">    1042</span>                 :<span class="tlaUNC">           0 :             num_chs += tensor2[b].channels;</span></span>
<span id="L1043"><span class="lineNum">    1043</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L1044"><span class="lineNum">    1044</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L1045"><span class="lineNum">    1045</span>                 :<span class="tlaUNC">           0 :         assign_tensor(&amp;tensor2[branch], output[output_num], num_chs, o_width,</span></span>
<span id="L1046"><span class="lineNum">    1046</span>                 :<span class="tlaUNC">           0 :                       o_height, out_stride[output_num]);</span></span>
<span id="L1047"><span class="lineNum">    1047</span>                 :             : </span>
<span id="L1048"><span class="lineNum">    1048</span>                 :<span class="tlaUNC">           0 :         num_chs = existing_channels;</span></span>
<span id="L1049"><span class="lineNum">    1049</span>                 :<span class="tlaUNC">           0 :         for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L1050"><span class="lineNum">    1050</span>                 :<span class="tlaUNC">           0 :           if ((branch_config-&gt;branches_to_combine &amp; (1 &lt;&lt; b)) &amp;&amp; b != branch) {</span></span>
<span id="L1051"><span class="lineNum">    1051</span>                 :             :             assert(check_tensor_equal_dims(&amp;tensor2[b], &amp;tensor2[branch]));</span>
<span id="L1052"><span class="lineNum">    1052</span>                 :             :             // Needed only to assign the new channel buffers</span>
<span id="L1053"><span class="lineNum">    1053</span>                 :<span class="tlaUNC">           0 :             copy_tensor(&amp;tensor2[b], tensor2[b].channels, num_chs,</span></span>
<span id="L1054"><span class="lineNum">    1054</span>                 :<span class="tlaUNC">           0 :                         &amp;tensor2[branch]);</span></span>
<span id="L1055"><span class="lineNum">    1055</span>                 :<span class="tlaUNC">           0 :             num_chs += tensor2[b].channels;</span></span>
<span id="L1056"><span class="lineNum">    1056</span>                 :<span class="tlaUNC">           0 :           }</span></span>
<span id="L1057"><span class="lineNum">    1057</span>                 :<span class="tlaUNC">           0 :         }</span></span>
<span id="L1058"><span class="lineNum">    1058</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L1059"><span class="lineNum">    1059</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L1060"><span class="lineNum">    1060</span>                 :             : </span>
<span id="L1061"><span class="lineNum">    1061</span>                 :<span class="tlaUNC">           0 :     if (layer_config-&gt;branch_copy_type == BRANCH_COMBINED) {</span></span>
<span id="L1062"><span class="lineNum">    1062</span>                 :<span class="tlaUNC">           0 :       if (!copy_active_tensor_to_branches(&amp;tensor2[branch], layer_config,</span></span>
<span id="L1063"><span class="lineNum">    1063</span>                 :<span class="tlaUNC">           0 :                                           branch, tensor2)) {</span></span>
<span id="L1064"><span class="lineNum">    1064</span>                 :<span class="tlaUNC">           0 :         goto Error;</span></span>
<span id="L1065"><span class="lineNum">    1065</span>                 :             :       }</span>
<span id="L1066"><span class="lineNum">    1066</span>                 :<span class="tlaUNC">           0 :     }</span></span>
<span id="L1067"><span class="lineNum">    1067</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L1068"><span class="lineNum">    1068</span>                 :             : </span>
<span id="L1069"><span class="lineNum">    1069</span>                 :<span class="tlaUNC">           0 :   success = true;</span></span>
<span id="L1070"><span class="lineNum">    1070</span>                 :             : Error:</span>
<span id="L1071"><span class="lineNum">    1071</span>                 :<span class="tlaUNC">           0 :   for (int b = 0; b &lt; CNN_MAX_BRANCHES; ++b) {</span></span>
<span id="L1072"><span class="lineNum">    1072</span>                 :<span class="tlaUNC">           0 :     free_tensor(&amp;tensor1[b]);</span></span>
<span id="L1073"><span class="lineNum">    1073</span>                 :<span class="tlaUNC">           0 :     free_tensor(&amp;tensor2[b]);</span></span>
<span id="L1074"><span class="lineNum">    1074</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L1075"><span class="lineNum">    1075</span>                 :<span class="tlaUNC">           0 :   return success;</span></span>
<span id="L1076"><span class="lineNum">    1076</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L1077"><span class="lineNum">    1077</span>                 :             : </span>
<span id="L1078"><span class="lineNum">    1078</span>                 :             : // Assume output already has proper allocation</span>
<span id="L1079"><span class="lineNum">    1079</span>                 :             : // Assume input image buffers all have same resolution and strides</span>
<span id="L1080"><span class="lineNum">    1080</span>                 :<span class="tlaUNC">           0 : bool av1_cnn_predict_img_multi_out(uint8_t **dgd, int width, int height,</span></span>
<span id="L1081"><span class="lineNum">    1081</span>                 :             :                                    int stride, const CNN_CONFIG *cnn_config,</span>
<span id="L1082"><span class="lineNum">    1082</span>                 :             :                                    const CNN_THREAD_DATA *thread_data,</span>
<span id="L1083"><span class="lineNum">    1083</span>                 :             :                                    CNN_MULTI_OUT *output) {</span>
<span id="L1084"><span class="lineNum">    1084</span>                 :<span class="tlaUNC">           0 :   const float max_val = 255.0;</span></span>
<span id="L1085"><span class="lineNum">    1085</span>                 :             : </span>
<span id="L1086"><span class="lineNum">    1086</span>                 :<span class="tlaUNC">           0 :   const int in_width = width + 2 * cnn_config-&gt;ext_width;</span></span>
<span id="L1087"><span class="lineNum">    1087</span>                 :<span class="tlaUNC">           0 :   const int in_height = height + 2 * cnn_config-&gt;ext_height;</span></span>
<span id="L1088"><span class="lineNum">    1088</span>                 :<span class="tlaUNC">           0 :   const int in_channels = cnn_config-&gt;layer_config[0].in_channels;</span></span>
<span id="L1089"><span class="lineNum">    1089</span>                 :<span class="tlaUNC">           0 :   float *inputs[CNN_MAX_CHANNELS];</span></span>
<span id="L1090"><span class="lineNum">    1090</span>                 :<span class="tlaUNC">           0 :   float *input_ =</span></span>
<span id="L1091"><span class="lineNum">    1091</span>                 :<span class="tlaUNC">           0 :       (float *)aom_malloc(in_width * in_height * in_channels * sizeof(*input_));</span></span>
<span id="L1092"><span class="lineNum">    1092</span>                 :<span class="tlaUNC">           0 :   if (!input_) return false;</span></span>
<span id="L1093"><span class="lineNum">    1093</span>                 :<span class="tlaUNC">           0 :   const int in_stride = in_width;</span></span>
<span id="L1094"><span class="lineNum">    1094</span>                 :             : </span>
<span id="L1095"><span class="lineNum">    1095</span>                 :<span class="tlaUNC">           0 :   for (int c = 0; c &lt; in_channels; ++c) {</span></span>
<span id="L1096"><span class="lineNum">    1096</span>                 :<span class="tlaUNC">           0 :     inputs[c] = input_ + c * in_stride * in_height;</span></span>
<span id="L1097"><span class="lineNum">    1097</span>                 :<span class="tlaUNC">           0 :     float *input =</span></span>
<span id="L1098"><span class="lineNum">    1098</span>                 :<span class="tlaUNC">           0 :         inputs[c] + cnn_config-&gt;ext_height * in_stride + cnn_config-&gt;ext_width;</span></span>
<span id="L1099"><span class="lineNum">    1099</span>                 :             : </span>
<span id="L1100"><span class="lineNum">    1100</span>                 :<span class="tlaUNC">           0 :     if (cnn_config-&gt;strict_bounds) {</span></span>
<span id="L1101"><span class="lineNum">    1101</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; height; ++i)</span></span>
<span id="L1102"><span class="lineNum">    1102</span>                 :<span class="tlaUNC">           0 :         for (int j = 0; j &lt; width; ++j)</span></span>
<span id="L1103"><span class="lineNum">    1103</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = (float)dgd[c][i * stride + j] / max_val;</span></span>
<span id="L1104"><span class="lineNum">    1104</span>                 :             :       // extend left and right</span>
<span id="L1105"><span class="lineNum">    1105</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; height; ++i) {</span></span>
<span id="L1106"><span class="lineNum">    1106</span>                 :<span class="tlaUNC">           0 :         for (int j = -cnn_config-&gt;ext_width; j &lt; 0; ++j)</span></span>
<span id="L1107"><span class="lineNum">    1107</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = input[i * in_stride];</span></span>
<span id="L1108"><span class="lineNum">    1108</span>                 :<span class="tlaUNC">           0 :         for (int j = width; j &lt; width + cnn_config-&gt;ext_width; ++j)</span></span>
<span id="L1109"><span class="lineNum">    1109</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = input[i * in_stride + width - 1];</span></span>
<span id="L1110"><span class="lineNum">    1110</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L1111"><span class="lineNum">    1111</span>                 :             :       // extend top and bottom</span>
<span id="L1112"><span class="lineNum">    1112</span>                 :<span class="tlaUNC">           0 :       for (int i = -cnn_config-&gt;ext_height; i &lt; 0; ++i)</span></span>
<span id="L1113"><span class="lineNum">    1113</span>                 :<span class="tlaUNC">           0 :         memcpy(&amp;input[i * in_stride - cnn_config-&gt;ext_width],</span></span>
<span id="L1114"><span class="lineNum">    1114</span>                 :<span class="tlaUNC">           0 :                &amp;input[-cnn_config-&gt;ext_width], in_width * sizeof(*input));</span></span>
<span id="L1115"><span class="lineNum">    1115</span>                 :<span class="tlaUNC">           0 :       for (int i = height; i &lt; height + cnn_config-&gt;ext_height; ++i)</span></span>
<span id="L1116"><span class="lineNum">    1116</span>                 :<span class="tlaUNC">           0 :         memcpy(&amp;input[i * in_stride - cnn_config-&gt;ext_width],</span></span>
<span id="L1117"><span class="lineNum">    1117</span>                 :<span class="tlaUNC">           0 :                &amp;input[(height - 1) * in_stride - cnn_config-&gt;ext_width],</span></span>
<span id="L1118"><span class="lineNum">    1118</span>                 :<span class="tlaUNC">           0 :                in_width * sizeof(*input));</span></span>
<span id="L1119"><span class="lineNum">    1119</span>                 :<span class="tlaUNC">           0 :     } else {</span></span>
<span id="L1120"><span class="lineNum">    1120</span>                 :<span class="tlaUNC">           0 :       for (int i = -cnn_config-&gt;ext_height; i &lt; height + cnn_config-&gt;ext_height;</span></span>
<span id="L1121"><span class="lineNum">    1121</span>                 :<span class="tlaUNC">           0 :            ++i)</span></span>
<span id="L1122"><span class="lineNum">    1122</span>                 :<span class="tlaUNC">           0 :         for (int j = -cnn_config-&gt;ext_width; j &lt; width + cnn_config-&gt;ext_width;</span></span>
<span id="L1123"><span class="lineNum">    1123</span>                 :<span class="tlaUNC">           0 :              ++j)</span></span>
<span id="L1124"><span class="lineNum">    1124</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = (float)dgd[c][i * stride + j] / max_val;</span></span>
<span id="L1125"><span class="lineNum">    1125</span>                 :             :     }</span>
<span id="L1126"><span class="lineNum">    1126</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L1127"><span class="lineNum">    1127</span>                 :<span class="tlaUNC">           0 :   bool success = av1_cnn_predict((const float **)inputs, in_width, in_height,</span></span>
<span id="L1128"><span class="lineNum">    1128</span>                 :<span class="tlaUNC">           0 :                                  in_stride, cnn_config, thread_data, output);</span></span>
<span id="L1129"><span class="lineNum">    1129</span>                 :             : </span>
<span id="L1130"><span class="lineNum">    1130</span>                 :<span class="tlaUNC">           0 :   aom_free(input_);</span></span>
<span id="L1131"><span class="lineNum">    1131</span>                 :<span class="tlaUNC">           0 :   return success;</span></span>
<span id="L1132"><span class="lineNum">    1132</span>                 :<span class="tlaUNC">           0 : }</span></span>
<span id="L1133"><span class="lineNum">    1133</span>                 :             : </span>
<span id="L1134"><span class="lineNum">    1134</span>                 :             : // Assume output already has proper allocation</span>
<span id="L1135"><span class="lineNum">    1135</span>                 :             : // Assume input image buffers all have same resolution and strides</span>
<span id="L1136"><span class="lineNum">    1136</span>                 :<span class="tlaUNC">           0 : bool av1_cnn_predict_img_multi_out_highbd(uint16_t **dgd, int width, int height,</span></span>
<span id="L1137"><span class="lineNum">    1137</span>                 :             :                                           int stride,</span>
<span id="L1138"><span class="lineNum">    1138</span>                 :             :                                           const CNN_CONFIG *cnn_config,</span>
<span id="L1139"><span class="lineNum">    1139</span>                 :             :                                           const CNN_THREAD_DATA *thread_data,</span>
<span id="L1140"><span class="lineNum">    1140</span>                 :             :                                           int bit_depth,</span>
<span id="L1141"><span class="lineNum">    1141</span>                 :             :                                           CNN_MULTI_OUT *output) {</span>
<span id="L1142"><span class="lineNum">    1142</span>                 :<span class="tlaUNC">           0 :   const float max_val = (float)((1 &lt;&lt; bit_depth) - 1);</span></span>
<span id="L1143"><span class="lineNum">    1143</span>                 :             : </span>
<span id="L1144"><span class="lineNum">    1144</span>                 :<span class="tlaUNC">           0 :   const int in_width = width + 2 * cnn_config-&gt;ext_width;</span></span>
<span id="L1145"><span class="lineNum">    1145</span>                 :<span class="tlaUNC">           0 :   const int in_height = height + 2 * cnn_config-&gt;ext_height;</span></span>
<span id="L1146"><span class="lineNum">    1146</span>                 :<span class="tlaUNC">           0 :   const int in_channels = cnn_config-&gt;layer_config[0].in_channels;</span></span>
<span id="L1147"><span class="lineNum">    1147</span>                 :<span class="tlaUNC">           0 :   float *inputs[CNN_MAX_CHANNELS];</span></span>
<span id="L1148"><span class="lineNum">    1148</span>                 :<span class="tlaUNC">           0 :   float *input_ =</span></span>
<span id="L1149"><span class="lineNum">    1149</span>                 :<span class="tlaUNC">           0 :       (float *)aom_malloc(in_width * in_height * in_channels * sizeof(*input_));</span></span>
<span id="L1150"><span class="lineNum">    1150</span>                 :<span class="tlaUNC">           0 :   if (!input_) return false;</span></span>
<span id="L1151"><span class="lineNum">    1151</span>                 :<span class="tlaUNC">           0 :   const int in_stride = in_width;</span></span>
<span id="L1152"><span class="lineNum">    1152</span>                 :             : </span>
<span id="L1153"><span class="lineNum">    1153</span>                 :<span class="tlaUNC">           0 :   for (int c = 0; c &lt; in_channels; ++c) {</span></span>
<span id="L1154"><span class="lineNum">    1154</span>                 :<span class="tlaUNC">           0 :     inputs[c] = input_ + c * in_stride * in_height;</span></span>
<span id="L1155"><span class="lineNum">    1155</span>                 :<span class="tlaUNC">           0 :     float *input =</span></span>
<span id="L1156"><span class="lineNum">    1156</span>                 :<span class="tlaUNC">           0 :         inputs[c] + cnn_config-&gt;ext_height * in_stride + cnn_config-&gt;ext_width;</span></span>
<span id="L1157"><span class="lineNum">    1157</span>                 :             : </span>
<span id="L1158"><span class="lineNum">    1158</span>                 :<span class="tlaUNC">           0 :     if (cnn_config-&gt;strict_bounds) {</span></span>
<span id="L1159"><span class="lineNum">    1159</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; height; ++i)</span></span>
<span id="L1160"><span class="lineNum">    1160</span>                 :<span class="tlaUNC">           0 :         for (int j = 0; j &lt; width; ++j)</span></span>
<span id="L1161"><span class="lineNum">    1161</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = (float)dgd[c][i * stride + j] / max_val;</span></span>
<span id="L1162"><span class="lineNum">    1162</span>                 :             :       // extend left and right</span>
<span id="L1163"><span class="lineNum">    1163</span>                 :<span class="tlaUNC">           0 :       for (int i = 0; i &lt; height; ++i) {</span></span>
<span id="L1164"><span class="lineNum">    1164</span>                 :<span class="tlaUNC">           0 :         for (int j = -cnn_config-&gt;ext_width; j &lt; 0; ++j)</span></span>
<span id="L1165"><span class="lineNum">    1165</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = input[i * in_stride];</span></span>
<span id="L1166"><span class="lineNum">    1166</span>                 :<span class="tlaUNC">           0 :         for (int j = width; j &lt; width + cnn_config-&gt;ext_width; ++j)</span></span>
<span id="L1167"><span class="lineNum">    1167</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = input[i * in_stride + width - 1];</span></span>
<span id="L1168"><span class="lineNum">    1168</span>                 :<span class="tlaUNC">           0 :       }</span></span>
<span id="L1169"><span class="lineNum">    1169</span>                 :             :       // extend top and bottom</span>
<span id="L1170"><span class="lineNum">    1170</span>                 :<span class="tlaUNC">           0 :       for (int i = -cnn_config-&gt;ext_height; i &lt; 0; ++i)</span></span>
<span id="L1171"><span class="lineNum">    1171</span>                 :<span class="tlaUNC">           0 :         memcpy(&amp;input[i * in_stride - cnn_config-&gt;ext_width],</span></span>
<span id="L1172"><span class="lineNum">    1172</span>                 :<span class="tlaUNC">           0 :                &amp;input[-cnn_config-&gt;ext_width], in_width * sizeof(*input));</span></span>
<span id="L1173"><span class="lineNum">    1173</span>                 :<span class="tlaUNC">           0 :       for (int i = height; i &lt; height + cnn_config-&gt;ext_height; ++i)</span></span>
<span id="L1174"><span class="lineNum">    1174</span>                 :<span class="tlaUNC">           0 :         memcpy(&amp;input[i * in_stride - cnn_config-&gt;ext_width],</span></span>
<span id="L1175"><span class="lineNum">    1175</span>                 :<span class="tlaUNC">           0 :                &amp;input[(height - 1) * in_stride - cnn_config-&gt;ext_width],</span></span>
<span id="L1176"><span class="lineNum">    1176</span>                 :<span class="tlaUNC">           0 :                in_width * sizeof(*input));</span></span>
<span id="L1177"><span class="lineNum">    1177</span>                 :<span class="tlaUNC">           0 :     } else {</span></span>
<span id="L1178"><span class="lineNum">    1178</span>                 :<span class="tlaUNC">           0 :       for (int i = -cnn_config-&gt;ext_height; i &lt; height + cnn_config-&gt;ext_height;</span></span>
<span id="L1179"><span class="lineNum">    1179</span>                 :<span class="tlaUNC">           0 :            ++i)</span></span>
<span id="L1180"><span class="lineNum">    1180</span>                 :<span class="tlaUNC">           0 :         for (int j = -cnn_config-&gt;ext_width; j &lt; width + cnn_config-&gt;ext_width;</span></span>
<span id="L1181"><span class="lineNum">    1181</span>                 :<span class="tlaUNC">           0 :              ++j)</span></span>
<span id="L1182"><span class="lineNum">    1182</span>                 :<span class="tlaUNC">           0 :           input[i * in_stride + j] = (float)dgd[c][i * stride + j] / max_val;</span></span>
<span id="L1183"><span class="lineNum">    1183</span>                 :             :     }</span>
<span id="L1184"><span class="lineNum">    1184</span>                 :<span class="tlaUNC">           0 :   }</span></span>
<span id="L1185"><span class="lineNum">    1185</span>                 :             : </span>
<span id="L1186"><span class="lineNum">    1186</span>                 :<span class="tlaUNC">           0 :   bool success = av1_cnn_predict((const float **)inputs, in_width, in_height,</span></span>
<span id="L1187"><span class="lineNum">    1187</span>                 :<span class="tlaUNC">           0 :                                  in_stride, cnn_config, thread_data, output);</span></span>
<span id="L1188"><span class="lineNum">    1188</span>                 :             : </span>
<span id="L1189"><span class="lineNum">    1189</span>                 :<span class="tlaUNC">           0 :   aom_free(input_);</span></span>
<span id="L1190"><span class="lineNum">    1190</span>                 :<span class="tlaUNC">           0 :   return success;</span></span>
<span id="L1191"><span class="lineNum">    1191</span>                 :<span class="tlaUNC">           0 : }</span></span>
        </pre>
              </td>
            </tr>
          </table>
          <br>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
            <tr><td class="versionInfo">Generated by: <a href="https://github.com//linux-test-project/lcov" target="_parent">LCOV version 2.0-1</a></td></tr>
          </table>
          <br>

</body>
</html>
